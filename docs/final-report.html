<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Final Report | Frank’s second book</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Final Report | Frank’s second book" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Final Report | Frank’s second book" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Frank Lin" />


<meta name="date" content="2022-05-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="applied-stats-model-ii-lecture-note.html"/>
<link rel="next" href="experimental-data-analysis.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Frank second book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html"><i class="fa fa-check"></i><b>1</b> Selling and buying process:</a>
<ul>
<li class="chapter" data-level="1.1" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#salespeople-skill-perception"><i class="fa fa-check"></i><b>1.1</b> Salespeople skill/ perception</a></li>
<li class="chapter" data-level="1.2" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#communication---intraorganization"><i class="fa fa-check"></i><b>1.2</b> Communication - intraorganization</a></li>
<li class="chapter" data-level="1.3" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#communication-interorganization---fle-interactions"><i class="fa fa-check"></i><b>1.3</b> Communication Interorganization - FLE interactions</a></li>
<li class="chapter" data-level="1.4" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#sales-marketing-interface"><i class="fa fa-check"></i><b>1.4</b> Sales marketing interface</a></li>
<li class="chapter" data-level="1.5" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#firm-level-impact-on-salespeople"><i class="fa fa-check"></i><b>1.5</b> Firm level impact on salespeople</a></li>
<li class="chapter" data-level="1.6" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#salesperson-trait-orientation"><i class="fa fa-check"></i><b>1.6</b> Salesperson trait orientation</a></li>
<li class="chapter" data-level="1.7" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#salesperson-non-sales-activity-service"><i class="fa fa-check"></i><b>1.7</b> Salesperson non-sales activity/ service</a></li>
<li class="chapter" data-level="1.8" data-path="selling-and-buying-process.html"><a href="selling-and-buying-process.html#b2g-selling"><i class="fa fa-check"></i><b>1.8</b> B2G selling</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="literature-review-note.html"><a href="literature-review-note.html"><i class="fa fa-check"></i><b>2</b> Literature Review Note</a>
<ul>
<li class="chapter" data-level="2.1" data-path="literature-review-note.html"><a href="literature-review-note.html#persuasion-knowledge-model-review"><i class="fa fa-check"></i><b>2.1</b> Persuasion knowledge Model Review</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="literature-review-note.html"><a href="literature-review-note.html#summary-for-pkm-in-online-environment"><i class="fa fa-check"></i><b>2.1.1</b> Summary for PKM in online environment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html"><i class="fa fa-check"></i><b>3</b> Database marketing substantive domain</a>
<ul>
<li class="chapter" data-level="3.1" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#key-issues"><i class="fa fa-check"></i><b>3.1</b> Key Issues</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#data-privacy"><i class="fa fa-check"></i><b>3.1.1</b> Data Privacy</a></li>
<li class="chapter" data-level="3.1.2" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#customer-lifetime-value-ltv"><i class="fa fa-check"></i><b>3.1.2</b> Customer lifetime value (LTV)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#method"><i class="fa fa-check"></i><b>3.2</b> Method</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#rfm"><i class="fa fa-check"></i><b>3.2.1</b> RFM</a></li>
<li class="chapter" data-level="3.2.2" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#market-basket-analysis"><i class="fa fa-check"></i><b>3.2.2</b> Market basket analysis</a></li>
<li class="chapter" data-level="3.2.3" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#collaborative-filtering"><i class="fa fa-check"></i><b>3.2.3</b> Collaborative filtering</a></li>
<li class="chapter" data-level="3.2.4" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#cluster-analysis"><i class="fa fa-check"></i><b>3.2.4</b> Cluster analysis</a></li>
<li class="chapter" data-level="3.2.5" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#decision-trees"><i class="fa fa-check"></i><b>3.2.5</b> Decision trees</a></li>
<li class="chapter" data-level="3.2.6" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#machine-learning"><i class="fa fa-check"></i><b>3.2.6</b> Machine learning</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#sub---substantive-areas"><i class="fa fa-check"></i><b>3.3</b> Sub - substantive areas</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#acquisition"><i class="fa fa-check"></i><b>3.3.1</b> Acquisition</a></li>
<li class="chapter" data-level="3.3.2" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#retention-churn-management"><i class="fa fa-check"></i><b>3.3.2</b> Retention/ Churn management</a></li>
<li class="chapter" data-level="3.3.3" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#cross-selling-and-up-selling"><i class="fa fa-check"></i><b>3.3.3</b> Cross-selling and up-selling</a></li>
<li class="chapter" data-level="3.3.4" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#reward-program"><i class="fa fa-check"></i><b>3.3.4</b> Reward program</a></li>
<li class="chapter" data-level="3.3.5" data-path="database-marketing-substantive-domain.html"><a href="database-marketing-substantive-domain.html#multichannel-customer"><i class="fa fa-check"></i><b>3.3.5</b> Multichannel customer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-scientist-job.html"><a href="data-scientist-job.html"><i class="fa fa-check"></i><b>4</b> Data Scientist Job</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-scientist-job.html"><a href="data-scientist-job.html#business-strategy-track-a.k.a-marketing-analytics"><i class="fa fa-check"></i><b>4.1</b> Business strategy Track (a.k.a Marketing Analytics)</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-scientist-job.html"><a href="data-scientist-job.html#database-marketing"><i class="fa fa-check"></i><b>4.1.1</b> Database marketing</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-scientist-job.html"><a href="data-scientist-job.html#programming"><i class="fa fa-check"></i><b>4.1.2</b> Programming</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-scientist-job.html"><a href="data-scientist-job.html#statistics"><i class="fa fa-check"></i><b>4.1.3</b> Statistics:</a></li>
<li class="chapter" data-level="4.1.4" data-path="data-scientist-job.html"><a href="data-scientist-job.html#visualization"><i class="fa fa-check"></i><b>4.1.4</b> Visualization</a></li>
<li class="chapter" data-level="4.1.5" data-path="data-scientist-job.html"><a href="data-scientist-job.html#automation"><i class="fa fa-check"></i><b>4.1.5</b> Automation</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-scientist-job.html"><a href="data-scientist-job.html#consumer-insight-track-aka.-marketing-research"><i class="fa fa-check"></i><b>4.2</b> Consumer insight Track (aka. Marketing Research)</a></li>
<li class="chapter" data-level="4.3" data-path="data-scientist-job.html"><a href="data-scientist-job.html#optimization-track-a.k.a-operational-research"><i class="fa fa-check"></i><b>4.3</b> Optimization Track (a.k.a Operational Research)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-scientist-job.html"><a href="data-scientist-job.html#model-optimization"><i class="fa fa-check"></i><b>4.3.1</b> Model optimization</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-scientist-job.html"><a href="data-scientist-job.html#macro-level-models"><i class="fa fa-check"></i><b>4.3.2</b> Macro level models</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-scientist-job.html"><a href="data-scientist-job.html#academic-paper-implementation"><i class="fa fa-check"></i><b>4.3.3</b> Academic Paper implementation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html"><i class="fa fa-check"></i><b>5</b> Marketing Strategy PhD skills</a>
<ul>
<li class="chapter" data-level="5.1" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#reading"><i class="fa fa-check"></i><b>5.1</b> Reading</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#meta-skill-to-gain"><i class="fa fa-check"></i><b>5.1.1</b> Meta skill to gain</a></li>
<li class="chapter" data-level="5.1.2" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#reading-purpose"><i class="fa fa-check"></i><b>5.1.2</b> Reading Purpose</a></li>
<li class="chapter" data-level="5.1.3" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#how-to-train"><i class="fa fa-check"></i><b>5.1.3</b> How to train</a></li>
<li class="chapter" data-level="5.1.4" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#suggested-reading-optional"><i class="fa fa-check"></i><b>5.1.4</b> Suggested reading (optional)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="marketing-strategy-phd-skills.html"><a href="marketing-strategy-phd-skills.html#writing"><i class="fa fa-check"></i><b>5.2</b> Writing</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html"><i class="fa fa-check"></i><b>6</b> Applied Stats Model II - Exam 1</a>
<ul>
<li class="chapter" data-level="6.1" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-in-a-poisson-regression-problem-with-one-explanatory-variable-x-the-estimate-of-the-β"><i class="fa fa-check"></i><b>6.1</b> 1. (7 points) In a poisson regression problem with one explanatory variable x, the estimate of the β</a></li>
<li class="chapter" data-level="6.2" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-in-a-generalized-linear-model-why-is-the-null-deviance-typically-larger-than-the-residual-deviance"><i class="fa fa-check"></i><b>6.2</b> 2. (5 points) In a generalized linear model, why is the null deviance typically larger than the residual deviance?</a></li>
<li class="chapter" data-level="6.3" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-can-standard-linear-regression-ever-be-used-when-the-data-are-counts-explain-why-or-why-not."><i class="fa fa-check"></i><b>6.3</b> 3. (5 points) Can standard linear regression ever be used when the data are counts? Explain why or why not.</a></li>
<li class="chapter" data-level="6.4" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#take-the-following-random-effect-model"><i class="fa fa-check"></i><b>6.4</b> 4. Take the following random effect model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#section"><i class="fa fa-check"></i><b>6.4.1</b> </a></li>
<li class="chapter" data-level="6.4.2" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-find-the-intra-class-correlation-coefficient."><i class="fa fa-check"></i><b>6.4.2</b> (3 points) Find the intra class correlation coefficient.</a></li>
<li class="chapter" data-level="6.4.3" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-which-level-of-the-random-effect-α-will-have-the-largest-predicted-value"><i class="fa fa-check"></i><b>6.4.3</b> (2 points) Which level of the random effect α will have the largest predicted value?</a></li>
<li class="chapter" data-level="6.4.4" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-predict-y-for-level-6-of-the-random-effect."><i class="fa fa-check"></i><b>6.4.4</b> (2 points) Predict y for level 6 of the random effect.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#utilizing-the-below-code-and-output-answer-the-following"><i class="fa fa-check"></i><b>6.5</b> 5. Utilizing the below code and output, answer the following:</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-why-are-the-residual-and-null-deviance-values-the-same"><i class="fa fa-check"></i><b>6.5.1</b> • (3 points) Why are the residual and null deviance values the same?</a></li>
<li class="chapter" data-level="6.5.2" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#points-based-on-these-deviance-values-does-the-model-fit-well-does-this-make-sense"><i class="fa fa-check"></i><b>6.5.2</b> • (2 points) Based on these deviance values, does the model “fit” well? Does this make sense?</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#take-the-data-given-by-problem6data.csv-which-contains-a-continuous-response-y-and-two-predictors-x1-and-x2."><i class="fa fa-check"></i><b>6.6</b> 6. Take the data given by Problem6Data.csv, which contains a continuous response y and two predictors x1 and x2.</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#a.-5-points-read-the-data-into-r-and-make-some-plots-between-the-response-and-predictors.-describe-the-patterns-and-comment-on-behaviors-you-observe-with-exact-0s."><i class="fa fa-check"></i><b>6.6.1</b> a. (5 points) Read the data into R and make some plots between the response and predictors. Describe the patterns and comment on behaviors you observe with exact 0s.</a></li>
<li class="chapter" data-level="6.6.2" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#b.-5-points-make-a-histogram-of-the-response-variable-and-comment-on-the-shape.-are-the-values-strictly-positive"><i class="fa fa-check"></i><b>6.6.2</b> b. (5 points) Make a histogram of the response variable and comment on the shape. Are the values strictly positive?</a></li>
<li class="chapter" data-level="6.6.3" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#c.-4-points-state-the-range-that-the-index-parameter-p-for-use-in-the-tweedie-distribution-must-be-contained-in.-why-is-this-the-case"><i class="fa fa-check"></i><b>6.6.3</b> c. (4 points) State the range that the index parameter p, for use in the Tweedie distribution, must be contained in. Why is this the case?</a></li>
<li class="chapter" data-level="6.6.4" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#d.-6-points-find-an-optimal-value-of-p-for-use-in-the-tweedie-distribution-using-a-log-link."><i class="fa fa-check"></i><b>6.6.4</b> d. (6 points) Find an optimal value of p for use in the Tweedie Distribution, using a log link.</a></li>
<li class="chapter" data-level="6.6.5" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#e.-5-points-again-using-a-log-link-fit-a-tweedie-distribution-using-the-index-parameter-value-you-obtained-in-part-d."><i class="fa fa-check"></i><b>6.6.5</b> e. (5 points) Again using a log link, fit a Tweedie Distribution using the index parameter value you obtained in part d.</a></li>
<li class="chapter" data-level="6.6.6" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#f.-6-points-for-each-of-the-values-of-x2-given-by-the-r-vector-x2_vals---seq0-15-by-.01-use-the-compound-poisson-gamma-structure-to-predict-the-probability-of-obtaining-an-exact-0-response-when-x1-is-at-its-mean-value."><i class="fa fa-check"></i><b>6.6.6</b> f. (6 points) For each of the values of x2 given by the R vector x2_vals &lt;- seq(0, 15, by= .01), use the compound Poisson-Gamma structure to predict the probability of obtaining an exact 0 response when x1 is at its mean value.</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#the-ships-dataset-in-the-mass-package-provides-the-number-of-incidentsindicents-resulting-in-ship-damage-as-a-function-of-total-months-of-serviceservice-ship-typetype-as-well-as-year-of-ship-constructionyear-broken-into-5-year-increments-with-the-years-variable-value-indicating-the-beginning-of-this-period.-e.g.-year60-refers-to-1960-1964-period-of-operationperiod-with-realizations-60-1960---1974-75-1975---1979-the-data-can-be-loaded-with-dataships-packagemass"><i class="fa fa-check"></i><b>6.7</b> 7. The ships dataset in the MASS package provides the number of incidents(indicents) resulting in ship damage as a function of total months of service(service), ship type(type), as well as: • Year of ship construction(year) – Broken into 5 year increments with the year’s variable value indicating the beginning of this period. e.g. year=60 refers to 1960-1964 • Period of operation(period) with realizations: – 60: 1960 - 1974 – 75: 1975 - 1979 The data can be loaded with: data(ships, package=“MASS”)</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#a.-4-points-use-group_by-and-summarise-to-compute-the-average-months-of-service-for-each-combination-of-year-of-construction-and-period-of-operation.-explain-why-there-is-a-0-in-the-result."><i class="fa fa-check"></i><b>6.7.1</b> a. (4 points) Use group_by and summarise to compute the average months of service for each combination of year of construction and period of operation. Explain why there is a 0 in the result.</a></li>
<li class="chapter" data-level="6.7.2" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#b.-3-points-create-a-new-filtered-dataset-by-removing-the-rows-where-service0."><i class="fa fa-check"></i><b>6.7.2</b> b. (3 points) Create a new filtered dataset by removing the rows where service=0.</a></li>
<li class="chapter" data-level="6.7.3" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#c.-10-points-fit-both-a-poisson-rate-model-and-negative-binomial-rate-model-model-using-number-of-incidents-per-service-month-as-the-response-and-all-other-variables-as-predictors.-compare-which-model-is-better-using-aic."><i class="fa fa-check"></i><b>6.7.3</b> c. (10 points) Fit both a Poisson rate model and Negative Binomial rate model model using number of incidents per service month as the response and all other variables as predictors. Compare which model is better using AIC.</a></li>
<li class="chapter" data-level="6.7.4" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#d.-7-points-using-the-better-model-selected-in-part-c-assess-the-significance-of-each-term-using-drop1.-which-terms-are-insignificant-remove-the-insignificant-variables-from-the-model-in-c-and-refit."><i class="fa fa-check"></i><b>6.7.4</b> d. (7 points) Using the better model selected in part c, assess the significance of each term using drop1(). Which terms are insignificant? Remove the insignificant variables from the model in c, and refit.</a></li>
<li class="chapter" data-level="6.7.5" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#e.-6-points-statistically-compare-the-residual-deviance-in-your-final-model-from-d-to-the-null-deviance."><i class="fa fa-check"></i><b>6.7.5</b> e. (6 points) Statistically compare the residual deviance in your final model from d to the null deviance.</a></li>
<li class="chapter" data-level="6.7.6" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#f.-4-points-compare-the-aic-from-the-reduced-model-in-d-to-the-corresponding-value-from-c.-is-the-change-you-see-expected-also-examine-the-residual-deviance-of-the-model-in-d-what-does-it-say-about-the-models-fit-to-the-data"><i class="fa fa-check"></i><b>6.7.6</b> f. (4 points) Compare the AIC from the reduced model in d to the corresponding value from c. Is the change you see expected? Also examine the residual deviance of the model in d, what does it say about the model’s fit to the data?</a></li>
<li class="chapter" data-level="6.7.7" data-path="applied-stats-model-ii---exam-1.html"><a href="applied-stats-model-ii---exam-1.html#g.-6-points-make-a-plot-of-the-deviance-residuals-vs-the-predicted-valueslink-scale.-how-is-the-fit"><i class="fa fa-check"></i><b>6.7.7</b> g. (6 points) Make a plot of the deviance residuals vs the predicted values(link scale). How is the fit?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><i class="fa fa-check"></i><b>7</b> Applied Stats Model II - Exam Two STAT 4520/7520 - Exam 2</a>
<ul>
<li class="chapter" data-level="7.1" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-consider-the-two-plots-below-which-show-the-exact-same-x-y-data.-the-difference-is-that-the-right-plot-has-colored-points-based-on-a-grouping-variable.-is-there-a-relationship-between-x-and-y-if-not-how-can-we-explain-the-left-plot-finally-how-would-you-model-the-response-y"><i class="fa fa-check"></i><b>7.1</b> 1. (7 points) Consider the two plots below, which show the exact same (x, y) data. The difference is that the right plot has colored points based on a grouping variable. Is there a relationship between x and y? If not, how can we explain the left plot? Finally, how would you model the response y?</a></li>
<li class="chapter" data-level="7.2" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-say-we-have-a-fitted-armapq-model-given-byy_t-.3y_t1-ε_t-what-are-the-values-of-p-and-q"><i class="fa fa-check"></i><b>7.2</b> 2. (3 points) Say we have a fitted ARMA(p,q) model given by<span class="math inline">\(Y_t = .3Y_{t−1} + ε_t\)</span> What are the values of p and q?</a></li>
<li class="chapter" data-level="7.3" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#say-we-observe-100-events-in-a-20ft-10ft-spatial-field-under-a-homogeneous-poisson-process"><i class="fa fa-check"></i><b>7.3</b> 3. Say we observe 100 events in a 20ft × 10ft spatial field under a homogeneous Poisson process:</a></li>
<li class="chapter" data-level="7.4" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-suppose-we-are-measuring-some-response-variable-and-our-data-contains-5-locations.-how-would-our-research-goals-be-different-if-we-considered-the-location-factor-as-fixed-vs-random"><i class="fa fa-check"></i><b>7.4</b> 4. (6 points) Suppose we are measuring some response variable and our data contains 5 locations. How would our research goals be different if we considered the location factor as fixed vs random?</a></li>
<li class="chapter" data-level="7.5" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-using-the-below-keras-code-and-summary-output-justify-the-number-of-parameters-at-each-layer-of-the-neural-network."><i class="fa fa-check"></i><b>7.5</b> 5. (7 points) Using the below keras code and summary output, justify the number of parameters at each layer of the neural network.</a></li>
<li class="chapter" data-level="7.6" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#consider-the-below-ann-which-was-fit-to-predict-a-cereals-rating-based-on-its-protein-content.-using-the-provided-weights-and-biases-with-an-input-of-protein4-find"><i class="fa fa-check"></i><b>7.6</b> 6. Consider the below ANN which was fit to predict a cereal’s rating based on its protein content. Using the provided weights and biases with an input of protein=4, find:</a></li>
<li class="chapter" data-level="7.7" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-consider-the-following-acf-plot."><i class="fa fa-check"></i><b>7.7</b> 7. (7 points) Consider the following ACF plot.</a></li>
<li class="chapter" data-level="7.8" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#points-the-file-1dconvolutiondata.csv-contains-a-collection-of-100-sequential-points.-read-them-into-r-and-convolve-them-with-the-kernal-c0.054-0.242-0.389-0.242-0.054.-place-the-orginal-signal-as-well-as-the-output-from-the-convolution-on-the-same-plotbe-sure-to-line-them-up-properly.-what-did-this-kernal-do"><i class="fa fa-check"></i><b>7.8</b> 8. (5 points) The file 1dConvolutionData.csv contains a collection of 100 sequential points. Read them into R and convolve them with the kernal c(0.054, 0.242, 0.389, 0.242, 0.054). Place the orginal signal as well as the output from the convolution on the same plot(be sure to line them up properly). What did this kernal do?</a></li>
<li class="chapter" data-level="7.9" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#time-series-20-points"><i class="fa fa-check"></i><b>7.9</b> 9. Time series (20 points)</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#a.-3-points-write-the-model-for-yt-mathematically-and-explain-the-intuition-behind-this-naming-convention."><i class="fa fa-check"></i><b>7.9.1</b> a. (3 points) Write the model for Yt mathematically and explain the intuition behind this naming convention.</a></li>
<li class="chapter" data-level="7.9.2" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#b.-6-points-using-a-random-error-process-of-ε-n0-1-start-a-random-walk-from-y_1-0-and-continue-for-1000-steps.-plot-the-time-series."><i class="fa fa-check"></i><b>7.9.2</b> b. (6 points) Using a random error process of ε ∼ N(0, 1), start a random walk from <span class="math inline">\(Y_1 = 0\)</span> and continue for 1000 steps. Plot the time series.</a></li>
<li class="chapter" data-level="7.9.3" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#c.-6-points-provide-both-an-autocorrelation-plot-as-well-as-a-partial-autocorrelation-plot.-explain-why-they-are-so-different."><i class="fa fa-check"></i><b>7.9.3</b> c. (6 points) Provide both an autocorrelation plot as well as a partial autocorrelation plot. Explain why they are so different.</a></li>
<li class="chapter" data-level="7.9.4" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#d.-5-points-change-the-value-of-φ"><i class="fa fa-check"></i><b>7.9.4</b> d. (5 points) Change the value of φ</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html"><a href="applied-stats-model-ii---exam-two-stat-45207520---exam-2.html#open-ended-analysis-in-r-29-points"><i class="fa fa-check"></i><b>7.10</b> 10. Open Ended Analysis in R (29 points)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="asm2-hw-term-project.html"><a href="asm2-hw-term-project.html"><i class="fa fa-check"></i><b>8</b> ASM2 HW Term Project</a>
<ul>
<li class="chapter" data-level="8.1" data-path="asm2-hw-term-project.html"><a href="asm2-hw-term-project.html#rq-what-workds-based-on-what-theory"><i class="fa fa-check"></i><b>8.1</b> RQ: what workds based on what theory</a></li>
<li class="chapter" data-level="8.2" data-path="asm2-hw-term-project.html"><a href="asm2-hw-term-project.html#descriptive-analysis"><i class="fa fa-check"></i><b>8.2</b> Descriptive analysis</a></li>
<li class="chapter" data-level="8.3" data-path="asm2-hw-term-project.html"><a href="asm2-hw-term-project.html#mixed-model"><i class="fa fa-check"></i><b>8.3</b> Mixed Model</a></li>
<li class="chapter" data-level="8.4" data-path="asm2-hw-term-project.html"><a href="asm2-hw-term-project.html#qa-a-why-small-change-b-prediction-measurement-auc-make-sense-c-interpretation-residual-centering-in-stats-vs.-econ."><i class="fa fa-check"></i><b>8.4</b> Q&amp;A: a) why small change b) prediction measurement, AUC make sense? c) interpretation residual centering in stats vs. econ.</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="question-1.html"><a href="question-1.html"><i class="fa fa-check"></i><b>9</b> Question 1:</a>
<ul>
<li class="chapter" data-level="9.1" data-path="question-1.html"><a href="question-1.html#a.-8-points-create-plots-to-examine-how-launch-speed-and-angle-may-affect-the-probability-of-a-home-run-and-describe-your-findings."><i class="fa fa-check"></i><b>9.1</b> a. (8 points) Create plots to examine how launch speed and angle may affect the probability of a home run and describe your findings.</a></li>
<li class="chapter" data-level="9.2" data-path="question-1.html"><a href="question-1.html#b.-9-points-fit-a-logistic-regression-model-with-home_run-as-the-response-and-all-other-variables-as-predictors.-conduct-a-deviance-test-to-assess-if-this-model-is-better-than-the-null-model."><i class="fa fa-check"></i><b>9.2</b> b. (9 points) Fit a logistic regression model with home_run as the response and all other variables as predictors. Conduct a deviance test to assess if this model is better than the null model.</a></li>
<li class="chapter" data-level="9.3" data-path="question-1.html"><a href="question-1.html#c.-8-points-conduct-deviance-tests-with-the-drop1-function-to-assess-the-significance-of-each-individual-variable-and-report-the-results.-compare-the-p-values-to-those-obtained-from-summary."><i class="fa fa-check"></i><b>9.3</b> c. (8 points) Conduct deviance tests with the drop1() function to assess the significance of each individual variable and report the results. Compare the p-values to those obtained from summary().</a></li>
<li class="chapter" data-level="9.4" data-path="question-1.html"><a href="question-1.html#d.-6-points-fit-a-smaller-model-after-removing-all-variables-which-are-insignificant-using-α-0.05.-compare-this-model-to-the-larger-model-are-they-significantly-different-what-are-the-implications-of-this-with-regard-to-model-selection-until-the-end-of-this-question-use-the-smaller-model-for-all-analysis"><i class="fa fa-check"></i><b>9.4</b> d. (6 points) Fit a smaller model after removing all variables which are insignificant using α = 0.05. Compare this model to the larger model, are they significantly different? What are the implications of this with regard to model selection? Until the end of this question, use the smaller model for all analysis</a></li>
<li class="chapter" data-level="9.5" data-path="question-1.html"><a href="question-1.html#e.-7-points-how-does-the-launch-speed-after-the-ball-is-hit-affect-the-odds-of-homerun-occurring-provide-a-confidence-interval-for-this-value."><i class="fa fa-check"></i><b>9.5</b> e. (7 points) How does the launch speed after the ball is hit affect the <strong>odds of HomeRun occurring</strong>? Provide a confidence interval for this value.</a></li>
<li class="chapter" data-level="9.6" data-path="question-1.html"><a href="question-1.html#f.-5-points-using-the-deviance-residuals-make-a-binned-residual-vs-fitted-probability-plot-and-comment-on-the-fit-of-the-model."><i class="fa fa-check"></i><b>9.6</b> f. (5 points) Using the deviance residuals, make a binned residual vs fitted probability plot and comment on the fit of the model.</a></li>
<li class="chapter" data-level="9.7" data-path="question-1.html"><a href="question-1.html#g.-4-points-using-a-probability-of-0.5-as-the-threshold-for-predicting-an-observation-yielding-a-home-run-create-a-table-classifying-the-predictions-against-the-observed-values.-describe-your-findings.-what-is-the-misclassification-rate"><i class="fa fa-check"></i><b>9.7</b> g. (4 points) Using a probability of 0.5 as the threshold for predicting an observation yielding a home run, create a table classifying the predictions against the observed values. Describe your findings. What is the misclassification rate?</a></li>
<li class="chapter" data-level="9.8" data-path="question-1.html"><a href="question-1.html#h.-6-points-using-probability-thresholds-from-0.005-to-0.995-obtain-the-sensitivities-and-specificity-of-the-resulting-predictions.-create-an-roc-plot-and-comment-on-the-effectiveness-of-the-models-ability-to-correctly-classify-the-response.-as-we-vary-the-threshold-to-determine-classifications-is-inverse-relationship-between-sensitivity-and-specificity-strongly-evident"><i class="fa fa-check"></i><b>9.8</b> h. (6 points) Using probability thresholds from 0.005 to 0.995, obtain the sensitivities and specificity of the resulting predictions. Create an ROC plot and comment on the effectiveness of the model’s ability to correctly classify the response. As we vary the threshold to determine classifications, is inverse relationship between sensitivity and specificity strongly evident?</a></li>
<li class="chapter" data-level="9.9" data-path="question-1.html"><a href="question-1.html#i.-5-points-produce-a-plot-of-the-sensitivity-and-specificity-against-the-threshold.-is-there-a-threshold-for-classification-you-would-recommend-that-provides-a-good-balance-between-the-two-make-another-confusion-matrix-using-this-cutoff-how-does-the-result-compare-to-the-previous-one-consider-the-types-of-errors-you-observe."><i class="fa fa-check"></i><b>9.9</b> i. (5 points) Produce a plot of the sensitivity and specificity against the threshold. Is there a threshold for classification you would recommend that provides a good balance between the two? Make another confusion matrix using this cutoff, how does the result compare to the previous one? Consider the types of errors you observe.</a></li>
<li class="chapter" data-level="9.10" data-path="question-1.html"><a href="question-1.html#j.-3-points-consider-a-logistic-model-with-only-launch_angle-and-launch_speed-being-used-to-predict-the-probability-of-a-home-run.-what-is-the-aic-of-this-model"><i class="fa fa-check"></i><b>9.10</b> j. (3 points) Consider a logistic model with only launch_angle and launch_speed being used to predict the probability of a home run. What is the AIC of this model?</a></li>
<li class="chapter" data-level="9.11" data-path="question-1.html"><a href="question-1.html#k.-11-points-create-a-dummy-variable-which-is-1-if-launch_angle-is-between-20-and-40-degrees-and-use-this-variable-in-your-model-instead-of-the-raw-value-for-launch_angle.-then-complete-the-following-1.-compare-the-aic-of-this-model-to-the-model-in-part-j-which-model-is-better-2.-what-does-the-coefficient-of-your-dummy-variable-mean-interpret-the-value.-3.-interpret-the-value-of-the-intercept-by-converting-to-a-probability.-does-this-result-make-sense"><i class="fa fa-check"></i><b>9.11</b> k. (11 points) Create a dummy variable which is 1 if launch_angle is between 20 and 40 degrees and use this variable in your model instead of the raw value for launch_angle. Then, complete the following: 1. Compare the AIC of this model to the model in part j, which model is better? 2. What does the coefficient of your dummy variable mean? Interpret the value. 3. Interpret the value of the intercept by converting to a probability. Does this result make sense?</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="question-1.html"><a href="question-1.html#section-1"><i class="fa fa-check"></i><b>9.11.1</b> </a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="question-1.html"><a href="question-1.html#a.-5-points-make-a-plot-or-set-of-tables-showing-the-distribution-of-lsd-use-between-genders-and-interpret.-you-can-use-code-similar-to-that-on-slide-84-of-the-course-notes."><i class="fa fa-check"></i><b>9.12</b> a. (5 points) Make a plot or set of tables showing the distribution of LSD use between genders and interpret. You can use code similar to that on slide 84 of the course notes.</a></li>
<li class="chapter" data-level="9.13" data-path="question-1.html"><a href="question-1.html#b.-9-points-fit-a-proportional-odds-model-using-lsd-as-the-response-variable-and-the-other-variables-listed-above-as-predictors.-using-drop1-test-if-the-variables-are-significant-or-insignificant-and-describe-2-your-results."><i class="fa fa-check"></i><b>9.13</b> b. (9 points) Fit a proportional odds model using LSD as the response variable and the other variables listed above as predictors. Using drop1(), test if the variables are significant or insignificant and describe 2 your results.</a></li>
<li class="chapter" data-level="9.14" data-path="question-1.html"><a href="question-1.html#c.-6-points-interpret-the-values-of-the-intercepts-θj-."><i class="fa fa-check"></i><b>9.14</b> c. (6 points) Interpret the values of the intercepts θj .</a></li>
<li class="chapter" data-level="9.15" data-path="question-1.html"><a href="question-1.html#d.-10-points-print-the-coefficient-table-and-interpret-the-values-of-the-significant-personality-characteristics."><i class="fa fa-check"></i><b>9.15</b> d. (10 points) Print the coefficient table and interpret the values of the significant personality characteristics.</a></li>
<li class="chapter" data-level="9.16" data-path="question-1.html"><a href="question-1.html#e.-7250-only-6-points-explore-interacting-some-of-the-categorical-demographic-variables-with-the-personality-measurements-and-report-your-findings-does-the-nature-of-any-personality-characteristics-affect-on-lsd-usage-change-according-to-your-analysis"><i class="fa fa-check"></i><b>9.16</b> e. (7250 only) (6 points) Explore interacting some of the categorical demographic variables with the personality measurements and report your findings, does the nature of any personality characteristics affect on LSD usage change according to your analysis?</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html"><i class="fa fa-check"></i><b>10</b> 1 1) Modeling the Number of Claims</a>
<ul>
<li class="chapter" data-level="10.1" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#a.-5-points-create-a-table-to-present-the-distribution-of-the-number-of-claims-by-computing-the-proportion-of-each-possibility.-what-percent-of-the-policies-have-0-claims"><i class="fa fa-check"></i><b>10.1</b> a. (5 points) Create a table to present the distribution of the number of claims by computing the proportion of each possibility. What percent of the policies have 0 claims?</a></li>
<li class="chapter" data-level="10.2" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#b.-6-points-create-a-poisson-regression-to-predict-the-number-of-claims-in-the-year-using-only-the-variables-for-vehicle-age-driver-age-bonusmalus-and-density.-what-is-the-deviance-does-is-differ-significantly-from-the-null-deviance"><i class="fa fa-check"></i><b>10.2</b> b. (6 points) Create a Poisson regression to predict the number of claims in the year using only the variables for vehicle age, driver age, bonusMalus, and density. What is the deviance? Does is differ significantly from the null deviance?</a></li>
<li class="chapter" data-level="10.3" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#c.-4-points-generate-predictions-on-the-response-scale-µ-and-round-them-to-the-nearest-count.-create-a-table-as-in-part-a-and-comment-on-how-similar-or-dissimilar-this-result-is."><i class="fa fa-check"></i><b>10.3</b> c. (4 points) Generate predictions on the response scale µ and round them to the nearest count. Create a table as in part a and comment on how similar or dissimilar this result is.</a></li>
<li class="chapter" data-level="10.4" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#d.-3-points-fit-a-negative-binomial-model-to-the-data-and-generate-predictions-as-in-part-c.-did-this-solve-the-problem"><i class="fa fa-check"></i><b>10.4</b> d. (3 points) Fit a negative binomial model to the data and generate predictions as in part c. Did this solve the problem?</a></li>
<li class="chapter" data-level="10.5" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#e.-5-points-now-fit-a-zero-inflation-poisson-model-zip-and-compute-the-fitted-proportion-of-zero-counts-as-on-slide-38-of-the-poisson-notes.-does-this-help"><i class="fa fa-check"></i><b>10.5</b> e. (5 points) Now fit a zero inflation Poisson model (ZIP) and compute the fitted proportion of zero counts as on slide 38 of the Poisson Notes. Does this help?</a></li>
<li class="chapter" data-level="10.6" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#f.-8-points-interpret-the-signs-of-the-coefficient-estimates-out-of-the-zip-model-both-the-count-portion-as-well-as-the-zero-inflated-portion"><i class="fa fa-check"></i><b>10.6</b> f. (8 points) Interpret the signs of the coefficient estimates out of the ZIP model, both the count portion as well as the zero inflated portion!</a></li>
<li class="chapter" data-level="10.7" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#a.-3-points-in-this-problem-we-will-focus-on-modeling-the-positive-continuous-variable-avgclaimamount.-attempt-to-fit-a-gamma-regression-with-a-log-link-predicting-avgclaimamount-as-a-function-of-all-feature-variables-in-the-dataset.-what-happens-when-you-attempt-to-fit-this-model"><i class="fa fa-check"></i><b>10.7</b> a. (3 points) In this problem we will focus on modeling the positive continuous variable “AvgClaimAmount.” Attempt to fit a Gamma regression with a log link, predicting AvgClaimAmount as a function of all feature variables in the dataset. What happens when you attempt to fit this model?</a></li>
<li class="chapter" data-level="10.8" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#b.-5-points-create-a-new-dataset-consisting-of-the-rows-that-correspond-to-strictly-positive-realizations-of-avgclaimamount.-make-a-histogram-of-this-variable-on-standard-and-log-scale-and-describe-your-findings."><i class="fa fa-check"></i><b>10.8</b> b. (5 points) Create a new dataset consisting of the rows that correspond to strictly positive realizations of AvgClaimAmount. Make a histogram of this variable on standard and log scale and describe your findings.</a></li>
<li class="chapter" data-level="10.9" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#c.-4-points-fit-the-gamma-regression-proposed-in-part-a-to-the-filtered-dataset.-do-you-notice-anything-strange-how-many-iterations-did-it-take-glm-to-find-this-result"><i class="fa fa-check"></i><b>10.9</b> c. (4 points) Fit the Gamma regression proposed in part a to the filtered dataset. Do you notice anything strange? How many iterations did it take glm() to find this result?</a></li>
<li class="chapter" data-level="10.10" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#d.-3-points-to-the-glm-function-add-the-argument-control-listmaxit-500.-what-do-you-think-this-will-do-fit-the-model-and-examine-the-summary-output-to-check-the-number-of-iterations-needed-for-convergence."><i class="fa fa-check"></i><b>10.10</b> d. (3 points) To the glm() function, add the argument control = list(maxit = 500). What do you think this will do? Fit the model and examine the summary output to check the number of iterations needed for convergence.</a></li>
<li class="chapter" data-level="10.11" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#e.3-points-from-the-model-in-e.-interpret-the-parameter-estimate-for-a-vehicles-age"><i class="fa fa-check"></i><b>10.11</b> e.(3 points) From the model in e. Interpret the parameter estimate for a vehicle’s age</a></li>
<li class="chapter" data-level="10.12" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#a.-8-points-using-the-entire-dataset-create-a-profile-likelihood-of-the-index-values-p-for-use-in-a-glm-utilizing-the-tweedie-distribution-to-predict-purepremium-directly.-make-a-plot-of-the-profile-likelihood-and-select-the-best-value.-7520---3-points-for-graduate-students-i-expect-some-exploration-to-find-the-best-value-as-these-data-are-quite-poorly-behaved.-look-at-the-value-section-of-tweedie.profile-for-some-hints-and-i-would-suggest-narrowing-the-search-space-for-p-and-evaluating-it-on-a-somewhat-fine-grid."><i class="fa fa-check"></i><b>10.12</b> a. (8 points) Using the entire dataset, create a profile likelihood of the index values p for use in a glm utilizing the Tweedie distribution to predict PurePremium directly. Make a plot of the profile likelihood and select the best value. (7520 - 3 points): For graduate students, I expect some <strong>exploration to find the best value as these data are quite poorly behaved</strong>. Look at the “Value” section of ?tweedie.profile for some hints, and I <strong>would suggest narrowing the search space for p and evaluating it on a somewhat fine grid.</strong></a></li>
<li class="chapter" data-level="10.13" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#b.-fit-the-tweedie-glm-model-using-the-optimal-power-value-you-computed-from-the-previous-question.-the-file-insurance_test.csv-contains-a-few-additional-observations-which-were-not-a-portion-of-the-data-used-to-fit-the-previous-models.-we-can-read-it-in-and-format-it-using-syntax-similar-to-when-we-started.-newdatapoints---read.csv.insurance_test.csv-newdatapointsvehbrand---as.factornewdatapointsvehbrand-newdatapointsvehpower---as.factornewdatapointsvehpower-newdatapointsvehgas---as.factornewdatapointsvehgas-newdatapointsregion---as.factornewdatapointsregion-newdatapointsarea---as.factornewdatapointsarea"><i class="fa fa-check"></i><b>10.13</b> b. Fit the Tweedie GLM model using the optimal power value you computed from the previous question. The file Insurance_test.csv contains a few additional observations which were not a portion of the data used to fit the previous models. We can read it in and format it using syntax similar to when we started. NewDataPoints &lt;- read.csv(“…./Insurance_test.csv”) NewDataPoints$VehBrand &lt;- as.factor(NewDataPoints$VehBrand) NewDataPoints$VehPower &lt;- as.factor(NewDataPoints$VehPower) NewDataPoints$VehGas &lt;- as.factor(NewDataPoints$VehGas) NewDataPoints$Region &lt;- as.factor(NewDataPoints$Region) NewDataPoints$Area &lt;- as.factor(NewDataPoints$Area)</a></li>
<li class="chapter" data-level="10.14" data-path="modeling-the-number-of-claims.html"><a href="modeling-the-number-of-claims.html#c.7-points-use-your-poisson-model-from-1b-from-and-your-final-gamma-model-from-2d-to-generate-respective-predictions-for-the-number-of-claims-in-a-year-as-well-as-the-average-amount-per-claim.-multiply-these-together-and-call-this-product-purepremium_prod.-similarly-use-your-tweedie-model-from-3b-to-directly-predict-the-purepremium-value-and-store-this-in-purepremium_tw."><i class="fa fa-check"></i><b>10.14</b> c.(7 points) Use your Poisson model from 1b from and your final Gamma model from 2d to generate respective predictions for the number of claims in a year as well as the average amount per claim. Multiply these together and call this product purepremium_prod. Similarly, use your Tweedie model from 3b to directly predict the PurePremium value and store this in purepremium_TW.</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><i class="fa fa-check"></i><b>11</b> STAT 4520/7520 - Homework 3 Spring 2022 Due: March 30, 2022</a>
<ul>
<li class="chapter" data-level="11.1" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#the-cake-dataset-in-the-lme4-package-contains-data-on-an-experiment-was-conducted-to-determine-the-effect-of-recipe-and-baking-temperature-on-chocolate-cake-quality.-fifteen-batches-of-cake-mix-for-each-recipe-were-prepared.-each-batch-was-sufficient-for-six-cakes.-each-of-the-six-cakes-was-baked-at-a-different-temperature-which-was-randomly-assigned.-as-an-indicator-of-quality-the-breakage-angle-of-the-cake-was-recorded."><i class="fa fa-check"></i><b>11.1</b> 1) The cake dataset in the lme4 package contains data on an experiment was conducted to determine the effect of recipe and baking temperature on chocolate cake quality. Fifteen batches of cake mix for each recipe were prepared. Each batch was sufficient for six cakes. Each of the six cakes was baked at a different temperature which was randomly assigned. As an indicator of quality, the breakage angle of the cake was recorded.</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#a.-of-the-explanatory-variables-recipe-temp-and-replicate-which-are-fixed-and-which-are-random-explain.-is-there-any-nesting-in-these-variables"><i class="fa fa-check"></i><b>11.1.1</b> a. Of the explanatory variables recipe, temp, and replicate, which are fixed and which are random? Explain. Is there any nesting in these variables?</a></li>
<li class="chapter" data-level="11.1.2" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#b.-fit-a-linear-model-with-no-random-effects-for-breaking-angle-against-the-interaction-between-recipe-and-temperature.-which-variables-are-significant-what-is-the-t-value-for-temp-the-temperature-variable-what-is-the-rmse-of-this-model"><i class="fa fa-check"></i><b>11.1.2</b> b. Fit a linear model with no random effects for breaking angle against the interaction between recipe and temperature. Which variables are significant? What is the t value for temp the temperature variable? What is the RMSE of this model?</a></li>
<li class="chapter" data-level="11.1.3" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#c.-fit-a-mixed-model-to-the-data-which-takes-into-account-the-replicates-of-the-recipes.-examine-the-variance-components.-is-there-variation-in-the-batches-made-with-each-recipe-how-does-the-residual-variance-component-compare-to-the-mse-from-b-what-is-the-t-value-for-temperature"><i class="fa fa-check"></i><b>11.1.3</b> c. Fit a mixed model to the data which takes into account the replicates of the recipes. Examine the variance components. Is there variation in the batches made with each recipe? How does the Residual variance component compare to the MSE from (b)? What is the t-value for temperature?</a></li>
<li class="chapter" data-level="11.1.4" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#d.-test-for-a-recipe-and-temperature-effect."><i class="fa fa-check"></i><b>11.1.4</b> d. Test for a recipe and temperature effect.</a></li>
<li class="chapter" data-level="11.1.5" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#e.-create-a-qq-plot-of-the-residuals-and-a-residual-vs-predicted-plot-for-the-linear-model-in-b-and-the-mixed-model-in-d-describe-how-well-the-model-assumptions-are-satisfied-for-each."><i class="fa fa-check"></i><b>11.1.5</b> e. Create a QQ plot of the residuals and a residual vs predicted plot for the linear model in (b) and the mixed model in (d), describe how well the model assumptions are satisfied for each.</a></li>
<li class="chapter" data-level="11.1.6" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#f.-7510-only-examine-the-blups-from-the-mixed-model-in-d.-do-you-notice-any-patterns"><i class="fa fa-check"></i><b>11.1.6</b> f. (7510 only) Examine the BLUPs from the mixed model in (d). Do you notice any patterns?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#the-purpose-of-random-effects-is-to-remove-variation-from-known-sources.-in-this-problem-we-will-use-this-idea-and-see-how-it-can-work-with-a-popular-technique-for-predictive-modeling-the-random-forest.-random-forests-were-covered-in-the-prerequisite-course-and-can-be-fit-using-the-randomforest-function-in-the-randomforest-library.-the-dataset-problem-2.csv-has-a-simulated-dataset.-there-is-a-nonlinear-relationship-between-6-numeric-explanatory-variables-x1-.-.-.-x6-and-the-response-y-to-addition-to-a-grouping-effect-according-to-the-id-variable-which-has-100-levels."><i class="fa fa-check"></i><b>11.2</b> 2) The purpose of random effects is to remove variation from known sources. In this problem, we will use this idea and see how it can work with a popular technique for predictive modeling, the random forest. Random forests were covered in the prerequisite course, and can be fit using the randomForest function in the randomForest library. The dataset Problem-2.csv has a simulated dataset. There is a nonlinear relationship between 6 numeric explanatory variables x1, . . . x6 and the response y, to addition to a grouping effect according to the ID variable, which has 100 levels.</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#a.-read-in-the-dataset-and-split-the-data-into-a-training-and-test-set-using-95-of-the-data-for-the-training-set.-set-a-seed-of-1-for-consistency-of-results."><i class="fa fa-check"></i><b>11.2.1</b> a. Read in the dataset, and split the data into a training and test set, using 95% of the data for the training set. Set a seed of 1 for consistency of results.</a></li>
<li class="chapter" data-level="11.2.2" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#b.-fit-a-random-forest-model-to-the-training-data-using-y-as-the-response-with-x1-.-.-.-x6-and-id-as-the-explanatory-variables.-use-the-model-to-predict-y-in-the-test-set-and-compute-the-test-root-mean-squared-error-rmse-."><i class="fa fa-check"></i><b>11.2.2</b> b. Fit a random forest model to the training data using y as the response with x1, . . . x6 and ID as the explanatory variables. Use the model to predict y in the test set and compute the test root mean squared error ( RMSE ).</a></li>
<li class="chapter" data-level="11.2.3" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#c.-fit-the-mixed-model-yij-µ-idi-εij-to-the-training-data.-this-model-does-not-use-the-x_i-at-all-and-has-a-random-intercept-based-on-id.-after-fitting-the-model-extract-the-blups-for-id-and-add-them-to-the-constant-µˆ-the-estimate-of-the-overall-intercept.-what-do-these-values-represent-store-them-in-a-data-frame-along-with-a-column-storing-the-ids."><i class="fa fa-check"></i><b>11.2.3</b> c. Fit the mixed model yij = µ + IDi + εij to the training data. This model does not use the x_i at all, and has a random intercept based on ID. After fitting the model, extract the BLUPs for ID and add them to the constant µˆ, the estimate of the overall intercept. What do these values represent? Store them in a data frame along with a column storing the IDs.</a></li>
<li class="chapter" data-level="11.2.4" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#d.-add-a-column-to-the-test-dataset-containing-the-values-obtained-in-part-c-joined-to-the-test-dataset-by-matching-the-ids.-note-with-the-dplyr-package-loaded-you-can-quickly-join-by-id-using-a-line-like-data.test---left_joindata.test-int_plus_blups-by-id-examine-the-first-few-rows-and-describe-what-the-new-column-represents."><i class="fa fa-check"></i><b>11.2.4</b> d. Add a column to the test dataset containing the values obtained in part c, joined to the test dataset by matching the IDs. Note: with the dplyr package loaded, you can quickly join by ID using a line like: Data.Test &lt;- left_join(Data.Test, int_plus_blups, by = “ID”) Examine the first few rows and describe what the new column represents.</a></li>
<li class="chapter" data-level="11.2.5" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#e.-compute-the-residuals-of-the-mixed-model-fit-in-c-using-the-residuals-function-store-them-in-a-column-of-the-training-data."><i class="fa fa-check"></i><b>11.2.5</b> e. Compute the residuals of the mixed model fit in (c) using the residuals() function, store them in a column of the training data.</a></li>
<li class="chapter" data-level="11.2.6" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#f.-fit-another-random-forest-model-to-the-training-data-using-the-residuals-from-part-e-as-the-response-and-only-x1-.-.-.-x6-as-the-explanatory-variables.-use-this-model-to-predict-into-the-test-data-and-store-these-predictions.-what-do-these-predictions-represent"><i class="fa fa-check"></i><b>11.2.6</b> f. Fit another random forest model to the training data, using the residuals from part (e) as the response and only x1, . . . x6 as the explanatory variables. Use this model to predict into the test data and store these predictions. What do these predictions represent?</a></li>
<li class="chapter" data-level="11.2.7" data-path="stat-45207520---homework-3-spring-2022-due-march-30-2022.html"><a href="stat-45207520---homework-3-spring-2022-due-march-30-2022.html#g.-add-the-predictions-in-f-to-the-values-joined-to-the-test-data-in-d.-consider-these-values-test-predictions-and-compute-the-test-mse.-compare-this-to-the-test-mse-compared-in-part-b.-what-do-you-observe"><i class="fa fa-check"></i><b>11.2.7</b> g. Add the predictions in (f) to the values joined to the test data in (d). Consider these values test predictions, and compute the test MSE. Compare this to the test MSE compared in part (b). What do you observe?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><i class="fa fa-check"></i><b>12</b> STAT 4520/7520 - Homework 4 Spring 2022 Due: April 25, 2022</a>
<ul>
<li class="chapter" data-level="12.1" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#section-2"><i class="fa fa-check"></i><b>12.1</b> 1)</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#a.-make-a-plot-of-weight-vs-time-for-the-data-with-rat-specific-lines-to-show-the-subject-specific-trajectory.-describe-your-findings.-7510-only-further-color-the-lines-differently-for-the-different-diets.-do-you-notice-anything-further"><i class="fa fa-check"></i><b>12.1.1</b> a. Make a plot of weight vs Time for the data with rat specific lines to show the subject specific trajectory. Describe your findings. (7510 only) Further, color the lines differently for the different diets. Do you notice anything further?</a></li>
<li class="chapter" data-level="12.1.2" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#b.-use-lm-to-regress-the-weight-onto-the-time.-what-is-the-slope-and-intercept-of-this-model-is-the-slope-significant"><i class="fa fa-check"></i><b>12.1.2</b> b. Use lm() to regress the weight onto the Time. What is the slope and intercept of this model? Is the slope significant?</a></li>
<li class="chapter" data-level="12.1.3" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#c.-use-the-lmlist-function-to-fit-a-linear-regression-model-that-describes-how-weight-varies-with-days-for-each-individual-rat.-how-do-the-slopes-and-intercepts-vary-do-you-notice-any-patterns-with-respect-to-diets"><i class="fa fa-check"></i><b>12.1.3</b> c. Use the lmList function to fit a linear regression model that describes how weight varies with days for each individual rat. How do the slopes and intercepts vary? Do you notice any patterns with respect to diets?</a></li>
<li class="chapter" data-level="12.1.4" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#d.-fit-a-random-intercept-model-to-account-for-the-different-weights-of-each-individual-rat-and-continue-to-use-time-as-a-fixed-effect.-answer-the-following"><i class="fa fa-check"></i><b>12.1.4</b> d. Fit a random intercept model to account for the different weights of each individual rat and continue to use Time as a fixed effect. Answer the following:</a></li>
<li class="chapter" data-level="12.1.5" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#e.-obtain-the-blups-for-the-rats-and-list-who-is-the-most-heavy."><i class="fa fa-check"></i><b>12.1.5</b> e. Obtain the BLUPs for the rats and list who is the most heavy.</a></li>
<li class="chapter" data-level="12.1.6" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#f.-fit-a-mixed-effects-model-that-describes-how-the-weight-varies-linearly-with-time-and-allows-for-random-variation-in-the-intercepts-and-slopes-of-the-rats.-then-do-the-following"><i class="fa fa-check"></i><b>12.1.6</b> f. Fit a mixed effects model that describes how the weight varies linearly with time and allows for random variation in the intercepts and slopes of the rats. Then do the following:</a></li>
<li class="chapter" data-level="12.1.7" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#g.-obtain-the-blups-for-the-model-in-part-f.-which-rat-has-the-fastest-rate-of-increase-the-slowest"><i class="fa fa-check"></i><b>12.1.7</b> g. Obtain the BLUPs for the model in part f. Which rat has the fastest rate of increase? The slowest?</a></li>
<li class="chapter" data-level="12.1.8" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#h.-add-the-fixed-diet-variable-to-the-model-in-the-form-of-an-interaction-with-time.-does-the-diet-effect-weight-is-this-effect-different-at-different-times"><i class="fa fa-check"></i><b>12.1.8</b> h. Add the (fixed) diet variable to the model in the form of an interaction with time. Does the diet effect weight? Is this effect different at different times?</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#time-series"><i class="fa fa-check"></i><b>12.2</b> 2) Time Series</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#a.-create-a-variable-containing-the-log-base-10-of-the-eps-then-use-lm-to-regress-it-onto-time.-store-the-residuals-of-this-regression-in-another-variable-in-jj.-make-a-plot-of-the-residuals-vs-time-and-describe-your-findings."><i class="fa fa-check"></i><b>12.2.1</b> a. Create a variable containing the log (base 10) of the EPS, then use lm() to regress it onto Time. Store the residuals of this regression in another variable in JJ. Make a plot of the residuals vs Time and describe your findings.</a></li>
<li class="chapter" data-level="12.2.2" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#b.-run-the-detrended-values-through-auto.arima-to-find-a-good-arma-model.-note-that-you-may-want-to-use-the-additional-argument-stepwise-false-to-allow-auto.arima-to-conduct-a-full-grid-search.-what-model-was-found"><i class="fa fa-check"></i><b>12.2.2</b> b. Run the detrended values through auto.arima() to find a good ARMA model. Note that you may want to use the additional argument stepwise = FALSE to allow auto.arima() to conduct a full grid search. What model was found?</a></li>
<li class="chapter" data-level="12.2.3" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#c.-use-the-best-model-to-forecast-the-detrended-relationship-2-years-8-quarters-ahead.-make-a-plot-of-the-result-and-comment-on-how-reasonable-your-predictions-look."><i class="fa fa-check"></i><b>12.2.3</b> c. Use the best model to forecast the detrended relationship 2 years (8 quarters) ahead. Make a plot of the result and comment on how reasonable your predictions look.</a></li>
<li class="chapter" data-level="12.2.4" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#d.-use-the-linear-model-from-part-a-to-predict-the-trend-for-the-next-8-quarters-add-the-result-to-that-of-part-c-transform-back-to-the-original-scale-and-plot-the-forecast-along-with-the-original-data.-does-the-forecast-seem-reasonable"><i class="fa fa-check"></i><b>12.2.4</b> d. Use the linear model from part a to predict the trend for the next 8 quarters, add the result to that of part c, transform back to the original scale, and plot the forecast along with the original data. Does the forecast seem reasonable?</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#spatial-point-process-analysis"><i class="fa fa-check"></i><b>12.3</b> 3) Spatial Point Process Analysis</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#a.-make-a-plot-of-the-point-pattern.-does-the-distribution-of-the-points-in-space-appear-to-be-homogeneous-poisson-process"><i class="fa fa-check"></i><b>12.3.1</b> a. Make a plot of the point pattern. Does the distribution of the points in space appear to be homogeneous Poisson process?</a></li>
<li class="chapter" data-level="12.3.2" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#b.-make-plots-of-gr-and-fr-and-comment-on-what-you-observe."><i class="fa fa-check"></i><b>12.3.2</b> b. Make plots of G(r) and F(r) and comment on what you observe.</a></li>
<li class="chapter" data-level="12.3.3" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#c.-fit-a-point-process-model-with-linear-terms-in-both-x-and-y.-are-there-any-significant-spatial-relationships"><i class="fa fa-check"></i><b>12.3.3</b> c. Fit a point process model with linear terms in both x and y. Are there any significant spatial relationships?</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#loading-keras"><i class="fa fa-check"></i><b>12.4</b> 4) Loading Keras</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#a.-mostly-as-an-exercise-to-ensure-you-have-keras-installed-correctly-run-the-above-code-and-comment-onthe-quality-of-the-fit-you-observe.-note-i-was-unable-to-run-the-code-within-an-rmarkdown-cell-but-this-may-be-due-to-a-system-configuration-issue."><i class="fa fa-check"></i><b>12.4.1</b> a. Mostly as an exercise to ensure you have Keras installed correctly, run the above code and comment onthe quality of the fit you observe. NOTE: I was unable to run the code within an RMarkdown cell, but this may be due to a system configuration issue.</a></li>
<li class="chapter" data-level="12.4.2" data-path="stat-45207520---homework-4-spring-2022-due-april-25-2022.html"><a href="stat-45207520---homework-4-spring-2022-due-april-25-2022.html#b.-modify-the-code-in-an-attempt-to-improve-the-fit.-specifically-study-the-effects-as-well-as-interactions-of"><i class="fa fa-check"></i><b>12.4.2</b> b. Modify the code in an attempt to improve the fit. Specifically, study the effects (as well as interactions) of:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html"><i class="fa fa-check"></i><b>13</b> Applied Stats Model II Lecture Note</a>
<ul>
<li class="chapter" data-level="13.1" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#list-of-questions"><i class="fa fa-check"></i><b>13.1</b> List of Questions:</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#hw1"><i class="fa fa-check"></i><b>13.1.1</b> HW1</a></li>
<li class="chapter" data-level="13.1.2" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#hw2"><i class="fa fa-check"></i><b>13.1.2</b> HW2</a></li>
<li class="chapter" data-level="13.1.3" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#midterm"><i class="fa fa-check"></i><b>13.1.3</b> Midterm</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#class-content-overview"><i class="fa fa-check"></i><b>13.2</b> Class content overview:</a></li>
<li class="chapter" data-level="13.3" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#glm-categoricaldata_sp2022"><i class="fa fa-check"></i><b>13.3</b> GLM-CategoricalData_SP2022</a></li>
<li class="chapter" data-level="13.4" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#glm-countdata_sp2022"><i class="fa fa-check"></i><b>13.4</b> GLM-CountData_SP2022</a></li>
<li class="chapter" data-level="13.5" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#glms_advancedtopics_sp2022"><i class="fa fa-check"></i><b>13.5</b> GLMs_AdvancedTopics_SP2022</a></li>
<li class="chapter" data-level="13.6" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#mm-randomeffects_spring2022"><i class="fa fa-check"></i><b>13.6</b> MM-RandomEffects_Spring2022</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="applied-stats-model-ii-lecture-note.html"><a href="applied-stats-model-ii-lecture-note.html#hw4-repeated-measure-time-and-space-dependence."><i class="fa fa-check"></i><b>13.6.1</b> HW4: Repeated measure, time and space dependence.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="final-report.html"><a href="final-report.html"><i class="fa fa-check"></i><b>14</b> Final Report</a>
<ul>
<li class="chapter" data-level="14.1" data-path="final-report.html"><a href="final-report.html#introduction"><i class="fa fa-check"></i><b>14.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="final-report.html"><a href="final-report.html#hypothesis"><i class="fa fa-check"></i><b>14.1.1</b> Hypothesis:</a></li>
<li class="chapter" data-level="14.1.2" data-path="final-report.html"><a href="final-report.html#data-background"><i class="fa fa-check"></i><b>14.1.2</b> Data Background</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="final-report.html"><a href="final-report.html#methodsanalysis"><i class="fa fa-check"></i><b>14.2</b> Methods/Analysis</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="final-report.html"><a href="final-report.html#empirical-analysis"><i class="fa fa-check"></i><b>14.2.1</b> Empirical Analysis</a></li>
<li class="chapter" data-level="14.2.2" data-path="final-report.html"><a href="final-report.html#impact-of-negotiation-tactics-on-the-likelihood-of-closing-sales"><i class="fa fa-check"></i><b>14.2.2</b> Impact of Negotiation Tactics on the Likelihood of Closing Sales</a></li>
<li class="chapter" data-level="14.2.3" data-path="final-report.html"><a href="final-report.html#research-implications"><i class="fa fa-check"></i><b>14.2.3</b> Research Implications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html"><i class="fa fa-check"></i><b>15</b> Experimental Data Analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html#process-macro"><i class="fa fa-check"></i><b>15.1</b> PROCESS Macro</a></li>
<li class="chapter" data-level="15.2" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html#data-cleaning"><i class="fa fa-check"></i><b>15.2</b> Data cleaning</a></li>
<li class="chapter" data-level="15.3" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html#mediation-analysis"><i class="fa fa-check"></i><b>15.3</b> Mediation analysis</a></li>
<li class="chapter" data-level="15.4" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html#adding-more-controls"><i class="fa fa-check"></i><b>15.4</b> Adding more controls</a></li>
<li class="chapter" data-level="15.5" data-path="experimental-data-analysis.html"><a href="experimental-data-analysis.html#efa-and-cfa-analysis-measurement-analysis"><i class="fa fa-check"></i><b>15.5</b> EFA And CFA Analysis / Measurement analysis</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><a href="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><i class="fa fa-check"></i><b>16</b> SEM HW5 - code in the chunk but don’t run them. copy them as a whole with the comments</a>
<ul>
<li class="chapter" data-level="16.1" data-path="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><a href="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html#replicate-hw3"><i class="fa fa-check"></i><b>16.1</b> Replicate HW3</a></li>
<li class="chapter" data-level="16.2" data-path="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><a href="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html#most-of-the-previous-steps-can-be-done-in-r-and-stata-in-parellel."><i class="fa fa-check"></i><b>16.2</b> most of the previous steps can be done in R and stata in parellel.</a></li>
<li class="chapter" data-level="16.3" data-path="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><a href="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html#output-the-write-up-in-the-r.-only-add-stata-as-complement.---use-tc-as-template."><i class="fa fa-check"></i><b>16.3</b> output the write up in the R. Only add Stata as complement. -&gt; use TC as template.</a></li>
<li class="chapter" data-level="16.4" data-path="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html"><a href="sem-hw5---code-in-the-chunk-but-dont-run-them.-copy-them-as-a-whole-with-the-comments.html#goal-is-to-understand-the-application-of-regression-at-different-angle-to-fully-understand-it."><i class="fa fa-check"></i><b>16.4</b> Goal is to understand the application of regression at different angle to fully understand it.</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Frank’s second book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="final-report" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">Chapter 14</span> Final Report<a href="final-report.html#final-report" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Introduction<a href="final-report.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sales negotiations over Internet-enabled live-chat portals are increasingly common in B2C durable product sales, but little is known about sales agent effectiveness in this context.
Drawing from theories of scarcity and information processing, this study conceptualizes three sales agent tactics— concession tactic, delay tactic, and value affirmation tactic—that interact to enhance the likelihood of closing sales.
Unique live-chat data and archival performance data before Covid (i.e., 2017) from a national home appliance retailer were employed to develop a validated corpus of textual cues to capture sales–agent closing tactics and test the proposed hypotheses.</p>
<p>Three tactics—the concession tactic, the value affirmation tactic, and the delay tactic—are key features of this theory that are interrelated with the heuristic processing mechanism. The concession tactic is defined as an agent’s offer or counter-offer to a customer’s bargaining request, along with other incentives to close the sale. For example, the salespeople will say:“I can give you $30 off”. It is measured as a dummy variable 0 or 1 since the concession amount tend to be fairly small (e.g., $30 off on major home appliance with averages about $600).
The value affirmation tactic is defined as an agent’s restatement of existing or advertised benefits to emphasize the perceived value of the purchase. For example, the salespeople will say:“the original price is $XXX, the sales price is $xxx, you are saving a lot!” or ” the washer has wrinkle free cleaning technology which brings your clothes like new”. It is measured as the percentage of the value affirmation tactic words out of the total salespeople words.
The delay tactic is defined as the time elapsed between the consumer’s bargaining request and the agent’s concession tactic or value affirmation tactic. It is measured as the actual time elapsed.
The research question is that what are the effective or ineffective combination of tactics on live chat sales closing with bargaining consumers.</p>
<div id="hypothesis" class="section level3 hasAnchor" number="14.1.1">
<h3><span class="header-section-number">14.1.1</span> Hypothesis:<a href="final-report.html#hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>H1: The concession tactic increases the likelihood of closing sales in bargaining during live chats between customers and sales agents.</p>
<p>H2: The delay tactic will positively moderate the concession tactic’s positive effect on the likelihood of a sales closing in bargaining live chats.</p>
<p>H3: The value affirmation tactic diminishes the positive effect of the concession tactic on the likelihood of closing the sale in bargaining live chats.</p>
</div>
<div id="data-background" class="section level3 hasAnchor" number="14.1.2">
<h3><span class="header-section-number">14.1.2</span> Data Background<a href="final-report.html#data-background" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I collaborated with a Fortune 500 national retailer to test the proposed framework with home appliance sales live chats (N = 975). The retailer was one of the top-three players in home appliance retailing when the data was collected. The retailer maintains a mix of online and in-store salespeople. Based on the research objective, I focused solely on live-chat salespeople. The retailer started conducting sales negotiations over live chat due to the shift from a traditional brick-and-mortar store to more online shopping. With e-retailing over big-ticket items becoming more of a trend, the retailer has formed a specialized home appliance live-chat sales team aiming to close more home appliance and extended warranty sales online. Home appliances account for a major part of the retailer’s business (more than 50%).</p>
<div id="sampling" class="section level4 hasAnchor" number="14.1.2.1">
<h4><span class="header-section-number">14.1.2.1</span> Sampling<a href="final-report.html#sampling" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following sampling criteria were used to meet the research objective.
(1) Salesperson and consumer live chat exchanged during B2C sales negotiations for 10 months in 2017 and one month in 2016.
I was advised to remove the period including major holiday seasons—Thanksgiving and Christmas (i.e., November, and December)—to ensure the results were generalizable for most of the time.
In addition, the promotion and policy are also substantively different during those two months per the managers’ interview.
(2) The chats need to take place at a later stage in the consumer decision journey (i.e., a specific product is discussed at the beginning of the live-chat sales interaction), since my dependent variable is objective sales closings.
The chats in the early stages cannot be closed during the chat or within a few days (usually captured by the system using browser cookies).
(3) New product purchase: The chats must be sales rather than service chats or products from a prior purchase, such as negotiating for better compensation.
Thus, the returned and exchanged related items are excluded.
Since my objective is to increase sales closings rather than satisfaction, I require the sales chats.
(5) The chats must contain the bargaining requests during the interactions—types of bargaining chats to be included and excluded in the study (e.g., not price matching type, not related to extended warranty bargaining, not initiated by the agent).
The reason for excluding the price matching type is that it is hard to differentiate it from the retailer’s specific policy.
They also are less generalizable to other contexts.</p>
</div>
<div id="unit-of-analysis" class="section level4 hasAnchor" number="14.1.2.2">
<h4><span class="header-section-number">14.1.2.2</span> Unit of Analysis<a href="final-report.html#unit-of-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Individual live chat is the unit of analysis—more specifically, the bargaining episode within the chat (i.e., after the consumer’s first bargaining request and before the order placement if the chat ends with a closed order).</p>
</div>
</div>
</div>
<div id="methodsanalysis" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Methods/Analysis<a href="final-report.html#methodsanalysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Since the live chats are nested within salespeople (i.e., a salesperson can have more than one chat during the period) and the outcome is a 0/1 dummy variable of actual order placement, I will use a generalized mixed model (i.e., logistic regression) with random effects to test the hypotheses. The agent ID is considered as random effect since I am not interested in any specific agent. They are random samples of larger group of agents.</p>
<div id="empirical-analysis" class="section level3 hasAnchor" number="14.2.1">
<h3><span class="header-section-number">14.2.1</span> Empirical Analysis<a href="final-report.html#empirical-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The chats’ sales outcome—closed or not closed—is represented by a binary choice that violates the assumption of the homoskedasticity of variance.
Thus, an MLE probit/logit will be more appropriate.
Moreover, the nested data structure (i.e., chats are nested within a salesperson) may lead to serial correlation in the error term and produce biased estimates if using traditional probit/logit regression.
Raudenbush and Anthony (2002) advocate the use of the hierarchical linear model (HLM) to account for the nested structure of the data by modeling within- and between- salesperson variances.
The mixed-effects model I employ in this study assumes that the two types of variations in effect sizes can be explained by the type of chat interaction variables, as well as other salesperson characteristics.
Thus, my model is as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="final-report.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#math syntax</span></span>
<span id="cb2-2"><a href="final-report.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#https://www.statpower.net/Content/310/R%20Stuff/SampleMarkdown.html</span></span>
<span id="cb2-3"><a href="final-report.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#??? How to display into multiple lines?</span></span>
<span id="cb2-4"><a href="final-report.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#??? I cannot knit it to specific folder</span></span></code></pre></div>
<p>Level 1 specification (i.e., each chat under the salesperson) <span class="math inline">\(Logit(PrY_{ij} = 1|X_{ij}) = log\frac{(PrY_{ij} = 1|X_{ij})} {(1-PrY_{ij} = 1|X_{ij})}\)</span></p>
<p><span class="math inline">\(\eta_{ij} = \beta_{0j} + \beta_{1}Concession_{ij} + \beta_{2}Delay_{ij} + \beta_{3}ValueAffirm_{ij} + \beta\_{4}Concession\_Delay\_{ij} + \beta\_{5}Concession\_ValueAffirm\_{ij} + \beta_{6}DRT_{ij} + \beta_{7}CBMind_{ij} + \beta_{8j}MCB_{ij} + \beta_{9}Altermode_{ij} + \beta_{10}Drcls_{ij} + \beta_{11}LSM_{ij} + \beta_{12}Deny_{ij} + \epsilon\_{ij}\)</span></p>
<p>where subscript (i) is the chat nested within salespeople (j).
“DlvrD” is the concession tactic, “Delay” is the delay tactic, “ValueAffirm” is the value affirmation tactic, “DRT” is the chat duration, “CBMind” is the consumer’s bargaining mindset, “MCB” is the consumers’ multiple distinct requests for bargaining, “Altermode” is the consumer’s alternative mode of communication, “Drcls” is the salespeople’s direct closing tactic, “LSM” is linguistic style matching, and “Deny” is the salespeople’s deny tactic.
The descriptive statistics can be found in Table 5.
The Level 1 equation describes the impact of chat interaction measures, whereas the Level 2 equation describes the effect of salesperson characteristics on the intercept in the Level 1 equation.
Consequently, my model follows: Intercept-as-outcome Model: <span class="math inline">\(\beta_{0j} = \gamma_{00} + \gamma_{01}HAChatcnt_j +_ \gamma{02}Team_j + u\_{0j} \$ \$ u\_{0j} \sim N(0,\tau\_{00})\)</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="final-report.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#??? should I model it as 1|AgentName + HAChatcnt + Team?</span></span></code></pre></div>
<p>“HAchatcnt” is salespeople’s experience with home appliance chats.
“Team” is the salespeople’s team status (home appliance or non-home appliance team).
Since cross-level interaction is not the research interest, I do not use the random coefficient specification.
I checked for multicollinearity using VIF.
The results demonstrate that the interaction term of delay tactic and concession tactic has a high VIF (close to 10).
I first tried to drop additional noncritical variables, but the procedure did not decrease the VIF.
Accordingly, I followed the residual centering procedure recommended in (Lance 1988; De Jong, De Ruyter, and Wetzels 2005; Y. Zhang et al. 2007).
After residual centering, all the VIFs are under 6, indicating that multicollinearity is not a concern.</p>
</div>
<div id="impact-of-negotiation-tactics-on-the-likelihood-of-closing-sales" class="section level3 hasAnchor" number="14.2.2">
<h3><span class="header-section-number">14.2.2</span> Impact of Negotiation Tactics on the Likelihood of Closing Sales<a href="final-report.html#impact-of-negotiation-tactics-on-the-likelihood-of-closing-sales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First, I explore the relationship between the dependent variable and the key independent variables.
Second, I fit the appropriate model with mulitple packages.
Third, I checked the model fit using deviance and ROC curve.
Fourth, I interpret the results with log transformation.</p>
<div id="exploratory-analysis-with-plots-of-the-data-andor-hypothesized-relationships-model-free-evidence." class="section level4 hasAnchor" number="14.2.2.1">
<h4><span class="header-section-number">14.2.2.1</span> Exploratory analysis with plots of the data and/or hypothesized relationships/ Model free evidence.<a href="final-report.html#exploratory-analysis-with-plots-of-the-data-andor-hypothesized-relationships-model-free-evidence." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="final-report.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="final-report.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Load dataset</span></span>
<span id="cb8-2"><a href="final-report.html#cb8-2" aria-hidden="true" tabindex="-1"></a>livechat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;E:/Cloud/OneDrive - University of Missouri/Webchat_Data_Stata/Webchat_201701_10_2016_10_fullcontrolidx.csv&quot;</span>, <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span>)</span>
<span id="cb8-3"><a href="final-report.html#cb8-3" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>AgentName <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(livechat<span class="sc">$</span>AgentName) <span class="co">#convert the categorical variable into the numeric variable for the nested structure.  </span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="final-report.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate new variables</span></span>
<span id="cb9-2"><a href="final-report.html#cb9-2" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>valcb_spwn <span class="ot">&lt;-</span> livechat<span class="sc">$</span>ValueCBWn<span class="sc">/</span>livechat<span class="sc">$</span>SlsPWn</span>
<span id="cb9-3"><a href="final-report.html#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#remove missing values</span></span>
<span id="cb9-4"><a href="final-report.html#cb9-4" aria-hidden="true" tabindex="-1"></a>livechat <span class="ot">&lt;-</span> <span class="fu">filter</span>(livechat, Delay_max <span class="sc">&gt;=</span><span class="dv">0</span> <span class="sc">&amp;</span> valcb_spwn <span class="sc">&gt;=</span> <span class="dv">0</span> <span class="sc">&amp;</span> earlycb <span class="sc">&gt;=</span> <span class="dv">0</span><span class="sc">&amp;</span> idx <span class="sc">!=</span> <span class="dv">102</span> <span class="sc">&amp;</span> idx <span class="sc">!=</span> <span class="dv">371</span><span class="sc">&amp;!</span><span class="fu">is.na</span>(HA_Cls)<span class="sc">&amp;!</span><span class="fu">is.na</span>(DlvrD)<span class="sc">&amp;!</span><span class="fu">is.na</span>(valcb_spwn)<span class="sc">&amp;!</span><span class="fu">is.na</span>(Delay_max)<span class="sc">&amp;!</span><span class="fu">is.na</span>(earlycb)<span class="sc">&amp;!</span><span class="fu">is.na</span>(LSM)<span class="sc">&amp;!</span><span class="fu">is.na</span>(EndChtD)<span class="sc">&amp;!</span><span class="fu">is.na</span>(MCB_IND)<span class="sc">&amp;!</span><span class="fu">is.na</span>(DrCls_IND)<span class="sc">&amp;!</span><span class="fu">is.na</span>(CB1BWn))</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="final-report.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filter to plot only when the concession is 1</span></span>
<span id="cb10-2"><a href="final-report.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://rforhr.com/filter.html</span></span>
<span id="cb10-3"><a href="final-report.html#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># cake &lt;- cake |&gt; dplyr::select(-temperature)</span></span>
<span id="cb10-4"><a href="final-report.html#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="final-report.html#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="final-report.html#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#standardize variables</span></span>
<span id="cb10-7"><a href="final-report.html#cb10-7" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>valcb_spwn_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>valcb_spwn)</span>
<span id="cb10-8"><a href="final-report.html#cb10-8" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>delay_max_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>Delay_max)</span>
<span id="cb10-9"><a href="final-report.html#cb10-9" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>drt_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>Drt) </span>
<span id="cb10-10"><a href="final-report.html#cb10-10" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>earlycb_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>earlycb)</span>
<span id="cb10-11"><a href="final-report.html#cb10-11" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>cb1bwn_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>CB1BWn)</span>
<span id="cb10-12"><a href="final-report.html#cb10-12" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>lsm_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>LSM)</span>
<span id="cb10-13"><a href="final-report.html#cb10-13" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>ha_chat_count_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>HA_Chat_count)</span>
<span id="cb10-14"><a href="final-report.html#cb10-14" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>earlycb_r <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">-</span> livechat<span class="sc">$</span>earlycb</span>
<span id="cb10-15"><a href="final-report.html#cb10-15" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>earlycb_r_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>earlycb_r)</span>
<span id="cb10-16"><a href="final-report.html#cb10-16" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>cb1bwn_std <span class="ot">&lt;-</span> <span class="fu">scale</span>(livechat<span class="sc">$</span>CB1BWn) </span>
<span id="cb10-17"><a href="final-report.html#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="final-report.html#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate new variables - standardized</span></span>
<span id="cb10-19"><a href="final-report.html#cb10-19" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>i_valcb_dlvr <span class="ot">&lt;-</span> livechat<span class="sc">$</span>valcb_spwn_std <span class="sc">*</span> livechat<span class="sc">$</span>DlvrD</span>
<span id="cb10-20"><a href="final-report.html#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="final-report.html#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create exploratory dataset</span></span>
<span id="cb10-22"><a href="final-report.html#cb10-22" aria-hidden="true" tabindex="-1"></a>livechat_concession <span class="ot">&lt;-</span> <span class="fu">filter</span>(livechat, DlvrD <span class="sc">==</span><span class="st">&quot;1&quot;</span>)</span>
<span id="cb10-23"><a href="final-report.html#cb10-23" aria-hidden="true" tabindex="-1"></a>livechat_NOconcession <span class="ot">&lt;-</span> <span class="fu">filter</span>(livechat, DlvrD <span class="sc">==</span><span class="st">&quot;0&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="final-report.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># group by the ID variable and get the count</span></span>
<span id="cb11-2"><a href="final-report.html#cb11-2" aria-hidden="true" tabindex="-1"></a>livechat_cnt <span class="ot">&lt;-</span> livechat <span class="sc">%&gt;%</span></span>
<span id="cb11-3"><a href="final-report.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">group_by</span>(AgtNm) <span class="sc">%&gt;%</span></span>
<span id="cb11-4"><a href="final-report.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summarise</span>(<span class="at">count=</span><span class="fu">n</span>()) </span>
<span id="cb11-5"><a href="final-report.html#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="final-report.html#cb11-6" aria-hidden="true" tabindex="-1"></a>livechat_cnt <span class="ot">&lt;-</span> <span class="fu">filter</span>(livechat_cnt, count <span class="sc">&gt;</span><span class="dv">1</span>) <span class="co"># remove the agents with only one chat to fulfill the requirement of the unbalanced panel for random and fixed effects. </span></span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="final-report.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Filter out the observations from the agent with less than 1 chat. </span></span>
<span id="cb12-2"><a href="final-report.html#cb12-2" aria-hidden="true" tabindex="-1"></a>livechat <span class="ot">&lt;-</span> livechat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(AgtNm <span class="sc">%in%</span> livechat_cnt<span class="sc">$</span>AgtNm)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="final-report.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Exploratory analysis on the response variable -&gt; histogram X -&gt; do the plot with key variables.</span></span>
<span id="cb13-2"><a href="final-report.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># seems like delay has a u shape while value affirmation is negative.</span></span>
<span id="cb13-3"><a href="final-report.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb13-4"><a href="final-report.html#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(HA_Cls) <span class="sc">~</span> delay_max_std,livechat_concession)</span>
<span id="cb13-5"><a href="final-report.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(HA_Cls) <span class="sc">~</span> delay_max_std,livechat_NOconcession)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-9-1.png" width="672" />
I notice that with concession, the delay tactic tends to increase the sales closing likelihood. When there is no concession, delay tactic tends to decrease the sales closing likelihood.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="final-report.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb14-2"><a href="final-report.html#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(HA_Cls) <span class="sc">~</span> valcb_spwn_std,livechat_concession)</span>
<span id="cb14-3"><a href="final-report.html#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.factor</span>(HA_Cls) <span class="sc">~</span> valcb_spwn_std,livechat_NOconcession)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-10-1.png" width="672" />
I notice that with concession, the value affirmation tactic tends to decrease the sales closing likelihood. When there is no concession, value affirmation tactic tends to have no effect on the sales closing likelihood.</p>
</div>
<div id="model-testing" class="section level4 hasAnchor" number="14.2.2.2">
<h4><span class="header-section-number">14.2.2.2</span> Model Testing<a href="final-report.html#model-testing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="final-report.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#test the VIF in pooled model </span></span>
<span id="cb15-2"><a href="final-report.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#https://stackoverflow.com/questions/20281055/test-for-multicollinearity-in-panel-data-r</span></span>
<span id="cb15-3"><a href="final-report.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.statology.org/variance-inflation-factor-r/</span></span>
<span id="cb15-4"><a href="final-report.html#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code></pre></div>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## 
## Attaching package: &#39;car&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     recode</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="final-report.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plm)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;plm&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     between, lag, lead</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="final-report.html#cb22-1" aria-hidden="true" tabindex="-1"></a>form <span class="ot">&lt;-</span> HA_Cls <span class="sc">~</span> DlvrD <span class="sc">+</span> delay_max_std <span class="sc">+</span> valcb_spwn_std <span class="sc">+</span> DlvrD<span class="sc">*</span>delay_max_std <span class="sc">+</span> DlvrD<span class="sc">*</span>valcb_spwn_std <span class="sc">+</span> drt_std <span class="sc">+</span> earlycb_r_std <span class="sc">+</span>  MCB_IND <span class="sc">+</span> cb1bwn_std <span class="sc">+</span> EndChtD <span class="sc">+</span> DrCls_IND <span class="sc">+</span> lsm_std <span class="sc">+</span> DnyD  <span class="sc">+</span> ha_chat_count_std <span class="sc">+</span> team_d</span>
<span id="cb22-2"><a href="final-report.html#cb22-2" aria-hidden="true" tabindex="-1"></a>HedStata_pool <span class="ot">&lt;-</span> <span class="fu">plm</span>(form, livechat, <span class="at">model =</span> <span class="st">&quot;pooling&quot;</span>, <span class="at">index =</span> <span class="st">&quot;AgentName&quot;</span>, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb22-3"><a href="final-report.html#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(HedStata_pool)</span></code></pre></div>
<pre><code>##                DlvrD        delay_max_std       valcb_spwn_std 
##             1.632637            10.754449             3.305531 
##              drt_std        earlycb_r_std              MCB_IND 
##             2.392625             2.289617             1.137726 
##           cb1bwn_std              EndChtD            DrCls_IND 
##             2.616199             1.036700             1.129779 
##              lsm_std                 DnyD    ha_chat_count_std 
##             1.304876             1.095309             2.203606 
##               team_d  DlvrD:delay_max_std DlvrD:valcb_spwn_std 
##             2.129254             9.525217             2.747582</code></pre>
<p>Since the VIFs are high for delay tactic and its interaction term with Concession tactic, I adopt the residual centering approach.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="final-report.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Residual centering to reduce the VIF</span></span>
<span id="cb24-2"><a href="final-report.html#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="final-report.html#cb24-3" aria-hidden="true" tabindex="-1"></a>lm_delay_dlvrd <span class="ot">&lt;-</span> <span class="fu">lm</span>(delay_max_std <span class="sc">~</span> DlvrD, livechat)</span>
<span id="cb24-4"><a href="final-report.html#cb24-4" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>delay_max_std_rc <span class="ot">&lt;-</span> <span class="fu">residuals</span>(lm_delay_dlvrd)</span>
<span id="cb24-5"><a href="final-report.html#cb24-5" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>i_delay_max_std_rc_dlvrd <span class="ot">&lt;-</span> livechat<span class="sc">$</span>delay_max_std_rc <span class="sc">*</span> livechat<span class="sc">$</span>DlvrD</span>
<span id="cb24-6"><a href="final-report.html#cb24-6" aria-hidden="true" tabindex="-1"></a>lm_i_delay_max_std_rc_dlvrd <span class="ot">&lt;-</span> <span class="fu">lm</span>(i_delay_max_std_rc_dlvrd <span class="sc">~</span> delay_max_std_rc <span class="sc">+</span> DlvrD, livechat)</span>
<span id="cb24-7"><a href="final-report.html#cb24-7" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>i_delay_max_std_rc_dlvrd_rc <span class="ot">&lt;-</span> <span class="fu">residuals</span>(lm_i_delay_max_std_rc_dlvrd)</span></code></pre></div>
<p>I then run the same hypothesized model with multiple packages to cross-validate the results.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="final-report.html#cb25-1" aria-hidden="true" tabindex="-1"></a>livechat_model <span class="ot">&lt;-</span> HA_Cls <span class="sc">~</span> DlvrD <span class="sc">+</span> delay_max_std <span class="sc">+</span> valcb_spwn_std <span class="sc">+</span> i_delay_max_std_rc_dlvrd_rc <span class="sc">+</span> i_valcb_dlvr <span class="sc">+</span> drt_std <span class="sc">+</span> earlycb_r_std <span class="sc">+</span>  MCB_IND <span class="sc">+</span> cb1bwn_std <span class="sc">+</span> EndChtD <span class="sc">+</span> DrCls_IND <span class="sc">+</span> lsm_std <span class="sc">+</span> DnyD  <span class="sc">+</span> ha_chat_count_std <span class="sc">+</span> team_d</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="final-report.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="final-report.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># glmer package </span></span>
<span id="cb28-2"><a href="final-report.html#cb28-2" aria-hidden="true" tabindex="-1"></a>livechat<span class="sc">$</span>AgentName <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(livechat<span class="sc">$</span>AgentName))</span>
<span id="cb28-3"><a href="final-report.html#cb28-3" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">glmer</span>(HA_Cls <span class="sc">~</span> DlvrD <span class="sc">+</span> delay_max_std <span class="sc">+</span> valcb_spwn_std <span class="sc">+</span> i_delay_max_std_rc_dlvrd_rc <span class="sc">+</span> i_valcb_dlvr <span class="sc">+</span> drt_std <span class="sc">+</span> earlycb_r_std <span class="sc">+</span>  MCB_IND <span class="sc">+</span> cb1bwn_std <span class="sc">+</span> EndChtD <span class="sc">+</span> DrCls_IND <span class="sc">+</span> lsm_std <span class="sc">+</span> DnyD  <span class="sc">+</span> ha_chat_count_std <span class="sc">+</span> team_d <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>AgentName), livechat, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;logit&quot;</span>))</span>
<span id="cb28-4"><a href="final-report.html#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm1)</span></code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## HA_Cls ~ DlvrD + delay_max_std + valcb_spwn_std + i_delay_max_std_rc_dlvrd_rc +  
##     i_valcb_dlvr + drt_std + earlycb_r_std + MCB_IND + cb1bwn_std +  
##     EndChtD + DrCls_IND + lsm_std + DnyD + ha_chat_count_std +  
##     team_d + (1 | AgentName)
##    Data: livechat
## 
##      AIC      BIC   logLik deviance df.resid 
##    863.8    946.0   -414.9    829.8      913 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -6.8241 -0.5277 -0.2577  0.5647  8.2472 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev.
##  AgentName (Intercept) 0.1225   0.3499  
## Number of obs: 930, groups:  AgentName, 58
## 
## Fixed effects:
##                             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                 -2.32147    0.42992  -5.400 6.67e-08 ***
## DlvrD                        0.38590    0.26491   1.457 0.145190    
## delay_max_std               -0.19081    0.11335  -1.683 0.092310 .  
## valcb_spwn_std              -0.06613    0.20191  -0.328 0.743274    
## i_delay_max_std_rc_dlvrd_rc  1.18547    0.43620   2.718 0.006573 ** 
## i_valcb_dlvr                -0.75076    0.25341  -2.963 0.003050 ** 
## drt_std                     -0.18079    0.12220  -1.479 0.139026    
## earlycb_r_std                1.43035    0.16500   8.669  &lt; 2e-16 ***
## MCB_IND                     -0.11749    0.20685  -0.568 0.570048    
## cb1bwn_std                   0.99563    0.16626   5.988 2.12e-09 ***
## EndChtD                     -1.33007    0.35797  -3.716 0.000203 ***
## DrCls_IND                    1.07907    0.24102   4.477 7.57e-06 ***
## lsm_std                      0.31074    0.11205   2.773 0.005552 ** 
## DnyD                        -0.16653    0.19821  -0.840 0.400807    
## ha_chat_count_std            0.31643    0.14081   2.247 0.024623 *  
## team_d                      -0.07721    0.36087  -0.214 0.830573    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>## 
## Correlation matrix not shown by default, as p = 16 &gt; 12.
## Use print(x, correlation=TRUE)  or
##     vcov(x)        if you need it</code></pre>
<pre><code>## optimizer (Nelder_Mead) convergence code: 0 (OK)
## Model failed to converge with max|grad| = 0.00302405 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="final-report.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(MASS)</span></span>
<span id="cb32-2"><a href="final-report.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#model42 = glmmPQL(Agent_inSe ~ Sum_Scar*FU_1min + Sum_Value*FU_1min</span></span>
<span id="cb32-3"><a href="final-report.html#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#                  + Sum_SalesClose + log(wn) +LSM,</span></span>
<span id="cb32-4"><a href="final-report.html#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#                  random = ~ 1|ID, data = data_survey, family = binomial)</span></span>
<span id="cb32-5"><a href="final-report.html#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#??? what&#39;s the sim ~1 why not 1|ID</span></span>
<span id="cb32-6"><a href="final-report.html#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="final-report.html#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="final-report.html#cb35-1" aria-hidden="true" tabindex="-1"></a>glmmPQL_re <span class="ot">&lt;-</span> <span class="fu">glmmPQL</span>(livechat_model, <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span><span class="sc">|</span>AgentName, <span class="at">data =</span> livechat, <span class="at">family =</span> binomial)</span></code></pre></div>
<pre><code>## iteration 1</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="final-report.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glmmPQL_re)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: livechat 
##   AIC BIC logLik
##    NA  NA     NA
## 
## Random effects:
##  Formula: ~1 | AgentName
##          (Intercept) Residual
## StdDev: 0.0001919795 1.026964
## 
## Variance function:
##  Structure: fixed weights
##  Formula: ~invwt 
## Fixed effects:  HA_Cls ~ DlvrD + delay_max_std + valcb_spwn_std + i_delay_max_std_rc_dlvrd_rc +      i_valcb_dlvr + drt_std + earlycb_r_std + MCB_IND + cb1bwn_std +      EndChtD + DrCls_IND + lsm_std + DnyD + ha_chat_count_std +      team_d 
##                                  Value Std.Error  DF   t-value p-value
## (Intercept)                 -2.2063583 0.3491458 858 -6.319304  0.0000
## DlvrD                        0.3848989 0.2714842 858  1.417758  0.1566
## delay_max_std               -0.1909658 0.1161801 858 -1.643705  0.1006
## valcb_spwn_std              -0.0439477 0.2057154 858 -0.213634  0.8309
## i_delay_max_std_rc_dlvrd_rc  1.1635117 0.4498096 858  2.586676  0.0099
## i_valcb_dlvr                -0.7557323 0.2600897 858 -2.905660  0.0038
## drt_std                     -0.1834711 0.1250643 858 -1.467014  0.1427
## earlycb_r_std                1.4201864 0.1688229 858  8.412284  0.0000
## MCB_IND                     -0.1123936 0.2117478 858 -0.530790  0.5957
## cb1bwn_std                   0.9892010 0.1703045 858  5.808424  0.0000
## EndChtD                     -1.3023946 0.3651669 858 -3.566573  0.0004
## DrCls_IND                    1.0558608 0.2453534 858  4.303428  0.0000
## lsm_std                      0.3102127 0.1143444 858  2.712969  0.0068
## DnyD                        -0.1746284 0.2025658 858 -0.862082  0.3889
## ha_chat_count_std            0.3109155 0.1369970 858  2.269506  0.0235
## team_d                      -0.1510360 0.2614313  56 -0.577727  0.5658
##  Correlation: 
##                             (Intr) DlvrD  dly_m_ vlcb__ i_____ i_vlc_ drt_st
## DlvrD                       -0.577                                          
## delay_max_std                0.156 -0.264                                   
## valcb_spwn_std              -0.360  0.404 -0.126                            
## i_delay_max_std_rc_dlvrd_rc -0.162  0.163 -0.257  0.152                     
## i_valcb_dlvr                 0.313 -0.134 -0.061 -0.758 -0.158              
## drt_std                      0.027  0.083 -0.409  0.101 -0.063  0.034       
## earlycb_r_std               -0.032 -0.039 -0.140  0.052  0.170 -0.089 -0.309
## MCB_IND                     -0.115 -0.089 -0.114 -0.012 -0.036 -0.031 -0.071
## cb1bwn_std                  -0.059  0.029  0.047  0.118  0.172 -0.103 -0.467
## EndChtD                     -0.089  0.006  0.015  0.008 -0.042 -0.009  0.024
## DrCls_IND                   -0.574 -0.024  0.090  0.086  0.028 -0.099 -0.089
## lsm_std                     -0.016  0.018 -0.066 -0.015 -0.004  0.000 -0.170
## DnyD                        -0.260  0.091 -0.055  0.021 -0.019 -0.001 -0.035
## ha_chat_count_std            0.236  0.052  0.113 -0.019  0.014 -0.033  0.064
## team_d                      -0.364 -0.040 -0.061 -0.008  0.020 -0.046  0.031
##                             erly__ MCB_IN cb1bw_ EndChD DC_IND lsm_st DnyD  
## DlvrD                                                                       
## delay_max_std                                                               
## valcb_spwn_std                                                              
## i_delay_max_std_rc_dlvrd_rc                                                 
## i_valcb_dlvr                                                                
## drt_std                                                                     
## earlycb_r_std                                                               
## MCB_IND                     -0.040                                          
## cb1bwn_std                   0.746  0.051                                   
## EndChtD                      0.008  0.014 -0.027                            
## DrCls_IND                   -0.072  0.006 -0.048  0.013                     
## lsm_std                     -0.122  0.019 -0.172 -0.087 -0.023              
## DnyD                        -0.067 -0.107  0.021  0.060  0.078 -0.067       
## ha_chat_count_std            0.030 -0.065  0.011  0.001 -0.025  0.013 -0.117
## team_d                      -0.004  0.059 -0.012 -0.001 -0.026 -0.031  0.053
##                             h_ch__
## DlvrD                             
## delay_max_std                     
## valcb_spwn_std                    
## i_delay_max_std_rc_dlvrd_rc       
## i_valcb_dlvr                      
## drt_std                           
## earlycb_r_std                     
## MCB_IND                           
## cb1bwn_std                        
## EndChtD                           
## DrCls_IND                         
## lsm_std                           
## DnyD                              
## ha_chat_count_std                 
## team_d                      -0.703
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -6.4283299 -0.5193227 -0.2582833  0.5676998  7.8729503 
## 
## Number of Observations: 930
## Number of Groups: 58</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="final-report.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># https://stackoverflow.com/questions/29764983/r-encode-character-variables-into-numeric</span></span>
<span id="cb39-2"><a href="final-report.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># encode in stata will translate string into numeric. in R, two steps are needed.</span></span>
<span id="cb39-3"><a href="final-report.html#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pglm)</span></code></pre></div>
<pre><code>## Loading required package: maxLik</code></pre>
<pre><code>## Loading required package: miscTools</code></pre>
<pre><code>## 
## Please cite the &#39;maxLik&#39; package as:
## Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.
## 
## If you have questions, suggestions, or comments regarding the &#39;maxLik&#39; package, please use a forum or &#39;tracker&#39; at maxLik&#39;s R-Forge site:
## https://r-forge.r-project.org/projects/maxlik/</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="final-report.html#cb43-1" aria-hidden="true" tabindex="-1"></a>pglm_re <span class="ot">&lt;-</span> <span class="fu">pglm</span>(form, livechat, <span class="at">model =</span> <span class="st">&quot;random&quot;</span>, <span class="at">index =</span> <span class="st">&quot;AgentName&quot;</span>, </span>
<span id="cb43-2"><a href="final-report.html#cb43-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">random.models =</span> <span class="fu">c</span>(<span class="st">&quot;within&quot;</span>, <span class="st">&quot;between&quot;</span>), <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb43-3"><a href="final-report.html#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="final-report.html#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pglm_re)</span></code></pre></div>
<pre><code>## --------------------------------------------
## Maximum Likelihood estimation
## Newton-Raphson maximisation, 8 iterations
## Return code 1: gradient close to zero (gradtol)
## Log-Likelihood: -414.9473 
## 17  free parameters
## Estimates:
##                        Estimate Std. error t value  Pr(&gt; t)    
## (Intercept)          -2.583e+00  3.855e-01  -6.699 2.09e-11 ***
## DlvrD                 7.451e-01  3.135e-01   2.377  0.01746 *  
## delay_max_std        -1.227e+00  4.295e-01  -2.858  0.00427 ** 
## valcb_spwn_std       -4.394e-02  1.986e-01  -0.221  0.82487    
## drt_std              -1.835e-01  1.207e-01  -1.520  0.12859    
## earlycb_r_std         1.420e+00  1.630e-01   8.714  &lt; 2e-16 ***
## MCB_IND              -1.124e-01  2.044e-01  -0.550  0.58243    
## cb1bwn_std            9.892e-01  1.644e-01   6.017 1.78e-09 ***
## EndChtD              -1.302e+00  3.525e-01  -3.695  0.00022 ***
## DrCls_IND             1.056e+00  2.368e-01   4.458 8.27e-06 ***
## lsm_std               3.102e-01  1.104e-01   2.810  0.00495 ** 
## DnyD                 -1.746e-01  1.955e-01  -0.893  0.37183    
## ha_chat_count_std     3.109e-01  1.322e-01   2.351  0.01872 *  
## team_d               -1.510e-01  2.524e-01  -0.598  0.54951    
## DlvrD:delay_max_std   1.164e+00  4.342e-01   2.680  0.00737 ** 
## DlvrD:valcb_spwn_std -7.557e-01  2.511e-01  -3.010  0.00261 ** 
## sigma                -1.565e-08  2.202e-01   0.000  1.00000    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## --------------------------------------------</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="final-report.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Test in Stata</span></span>
<span id="cb45-2"><a href="final-report.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://stackoverflow.com/questions/59923956/trying-to-reproduce-xtreg-in-stata-with-plm-in-r</span></span>
<span id="cb45-3"><a href="final-report.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co">#plm vs. stata: https://cran.r-project.org/web/packages/plm/vignettes/A_plmPackage.html</span></span>
<span id="cb45-4"><a href="final-report.html#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># https://cran.r-project.org/web/packages/plm/vignettes/B_plmFunction.html</span></span>
<span id="cb45-5"><a href="final-report.html#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RStata)</span>
<span id="cb45-6"><a href="final-report.html#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="st">&quot;RStata.StataPath&quot;</span> <span class="ot">=</span> <span class="st">&quot;</span><span class="sc">\&quot;</span><span class="st">E:</span><span class="sc">\\</span><span class="st">Cloud</span><span class="sc">\\</span><span class="st">OneDrive - University of Missouri</span><span class="sc">\\</span><span class="st">Program</span><span class="sc">\\</span><span class="st">Stata 16</span><span class="sc">\\</span><span class="st">StataMP-64</span><span class="sc">\&quot;</span><span class="st">&quot;</span>)</span>
<span id="cb45-7"><a href="final-report.html#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="st">&quot;RStata.StataVersion&quot;</span> <span class="ot">=</span> <span class="dv">16</span>)</span>
<span id="cb45-8"><a href="final-report.html#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Stata fe </span></span>
<span id="cb45-9"><a href="final-report.html#cb45-9" aria-hidden="true" tabindex="-1"></a>stata_do1 <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb45-10"><a href="final-report.html#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="st">xtset AgentName</span></span>
<span id="cb45-11"><a href="final-report.html#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="st">xtlogit HA_Cls  DlvrD delay_max_std valcb_spwn_std i_delay_max_std_rc_dlvrd_rc i_valcb_dlvr drt_std earlycb_r_std MCB_IND cb1bwn_std EndChtD DrCls_IND lsm_std DnyD ha_chat_count_std team_d, re vce(cluster AgentName) </span></span>
<span id="cb45-12"><a href="final-report.html#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="st">estat ic</span></span>
<span id="cb45-13"><a href="final-report.html#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="st">estimates store re</span></span>
<span id="cb45-14"><a href="final-report.html#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="st">estimates table, star(.1 .05 .01)</span></span>
<span id="cb45-15"><a href="final-report.html#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="st">collin DlvrD delay_max_std valcb_spwn_std i_delay_max_std_rc_dlvrd_rc i_valcb_dlvr drt_std earlycb_r_std MCB_IND cb1bwn_std EndChtD DrCls_IND lsm_std DnyD ha_chat_count_std team_d</span></span>
<span id="cb45-16"><a href="final-report.html#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb45-17"><a href="final-report.html#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="fu">stata</span>(stata_do1, <span class="at">data.out =</span> <span class="cn">TRUE</span>, <span class="at">data.in =</span> livechat)</span></code></pre></div>
<pre><code>## . 
## . xtset AgentName
##        panel variable:  AgentName (unbalanced)
## . xtlogit HA_Cls  DlvrD delay_max_std valcb_spwn_std i_delay_max_std_rc_dlvrd_r
## &gt; c i_valcb_dlvr drt_std earlycb_r_std MCB_IND cb1bwn_std EndChtD DrCls_IND lsm
## &gt; _std DnyD ha_chat_count_std team_d, re vce(cluster AgentName) 
## 
## Fitting comparison model:
## 
## Iteration 0:   log pseudolikelihood = -561.16066  
## Iteration 1:   log pseudolikelihood = -426.71104  
## Iteration 2:   log pseudolikelihood = -415.11417  
## Iteration 3:   log pseudolikelihood = -414.94751  
## Iteration 4:   log pseudolikelihood = -414.94733  
## Iteration 5:   log pseudolikelihood = -414.94733  
## 
## Fitting full model:
## 
## tau =  0.0     log pseudolikelihood = -414.94733
## tau =  0.1     log pseudolikelihood = -415.03696
## 
## Iteration 0:   log pseudolikelihood = -414.99631  
## Iteration 1:   log pseudolikelihood = -414.89504  
## Iteration 2:   log pseudolikelihood = -414.89389  
## Iteration 3:   log pseudolikelihood = -414.89389  
## 
## Calculating robust standard errors:
## 
## Random-effects logistic regression              Number of obs     =        930
## Group variable: AgentName                       Number of groups  =         58
## 
## Random effects u_i ~ Gaussian                   Obs per group:
##                                                               min =          2
##                                                               avg =       16.0
##                                                               max =        351
## 
## Integration method: mvaghermite                 Integration pts.  =         12
## 
##                                                 Wald chi2(15)     =     255.05
## Log pseudolikelihood  = -414.89389              Prob &gt; chi2       =     0.0000
## 
##                              (Std. Err. adjusted for 58 clusters in AgentName)
## ------------------------------------------------------------------------------
##              |               Robust
##       HA_Cls |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
## -------------+----------------------------------------------------------------
##        DlvrD |    .385579   .3158987     1.22   0.222    -.2335709    1.004729
## delay_max_~d |  -.1906206   .1201732    -1.59   0.113    -.4261558    .0449146
## valcb_spwn~d |  -.0672466   .1878915    -0.36   0.720    -.4355073     .301014
## i_delay_ma~c |   1.186531   .4698723     2.53   0.012     .2655984    2.107464
## i_valcb_dlvr |  -.7505258   .2130321    -3.52   0.000    -1.168061   -.3329906
##      drt_std |  -.1806803    .104897    -1.72   0.085    -.3862746    .0249139
## earlycb_r_~d |   1.430746   .2075747     6.89   0.000     1.023907    1.837585
##      MCB_IND |   -.117857   .1653891    -0.71   0.476    -.4420137    .2062997
##   cb1bwn_std |   .9958436    .169694     5.87   0.000     .6632495    1.328438
##      EndChtD |   -1.33118   .2779074    -4.79   0.000    -1.875869   -.7864917
##    DrCls_IND |   1.080619   .1671432     6.47   0.000     .7530239    1.408213
##      lsm_std |   .3107507   .0897694     3.46   0.001     .1348059    .4866956
##         DnyD |  -.1660678   .2234209    -0.74   0.457    -.6039646    .2718291
## ha_chat_co~d |   .3167114   .0817124     3.88   0.000     .1565581    .4768648
##       team_d |  -.0749339   .2836272    -0.26   0.792     -.630833    .4809652
##        _cons |   -2.32591   .3218474    -7.23   0.000    -2.956719   -1.695101
## -------------+----------------------------------------------------------------
##     /lnsig2u |  -2.044675   2.012963                     -5.990009    1.900659
## -------------+----------------------------------------------------------------
##      sigma_u |    .359753   .3620846                      .0500364    2.586561
##          rho |   .0378506   .0733079                      .0007604    .6703594
## ------------------------------------------------------------------------------
## . estat ic
## 
## Akaike&#39;s information criterion and Bayesian information criterion
## 
## -----------------------------------------------------------------------------
##        Model |          N   ll(null)  ll(model)      df        AIC        BIC
## -------------+---------------------------------------------------------------
##            . |        930          .  -414.8939      17   863.7878   945.9859
## -----------------------------------------------------------------------------
## Note: BIC uses N = number of observations. See [R] BIC note.
## . estimates store re
## . estimates table, star(.1 .05 .01)
## 
## ------------------------------
##     Variable |      re        
## -------------+----------------
## HA_Cls       |
##        DlvrD |  .38557905     
## delay_max_~d | -.19062062     
## valcb_spwn~d | -.06724665     
## i_delay_ma~c |  1.1865311**   
## i_valcb_dlvr | -.75052577***  
##      drt_std | -.18068031*    
## earlycb_r_~d |  1.4307463***  
##      MCB_IND | -.11785698     
##   cb1bwn_std |  .99584358***  
##      EndChtD | -1.3311803***  
##    DrCls_IND |  1.0806185***  
##      lsm_std |  .31075074***  
##         DnyD | -.16606776     
## ha_chat_co~d |  .31671145***  
##       team_d | -.07493386     
##        _cons | -2.3259101***  
## -------------+----------------
##     /lnsig2u | -2.0446754     
## ------------------------------
## legend: * p&lt;.1; ** p&lt;.05; *** p&lt;.01
## . collin DlvrD delay_max_std valcb_spwn_std i_delay_max_std_rc_dlvrd_rc i_valcb
## &gt; _dlvr drt_std earlycb_r_std MCB_IND cb1bwn_std EndChtD DrCls_IND lsm_std DnyD
## &gt;  ha_chat_count_std team_d
## (obs=930)
## 
##   Collinearity Diagnostics
## 
##                         SQRT                   R-
##   Variable      VIF     VIF    Tolerance    Squared
## ----------------------------------------------------
##      DlvrD      1.40    1.18    0.7130      0.2870
## delay_max_std      1.89    1.37    0.5291      0.4709
## valcb_spwn_std      3.31    1.82    0.3025      0.6975
## i_delay_max_std_rc_dlvrd_rc      1.04    1.02    0.9651      0.0349
## i_valcb_dlvr      2.75    1.66    0.3640      0.6360
##    drt_std      2.39    1.55    0.4180      0.5820
## earlycb_r_std      2.29    1.51    0.4368      0.5632
##    MCB_IND      1.14    1.07    0.8789      0.1211
## cb1bwn_std      2.62    1.62    0.3822      0.6178
##    EndChtD      1.04    1.02    0.9646      0.0354
##  DrCls_IND      1.13    1.06    0.8851      0.1149
##    lsm_std      1.30    1.14    0.7664      0.2336
##       DnyD      1.10    1.05    0.9130      0.0870
## ha_chat_count_std      2.20    1.48    0.4538      0.5462
##     team_d      2.13    1.46    0.4696      0.5304
## ----------------------------------------------------
##   Mean VIF      1.85
## 
##                            Cond
##         Eigenval          Index
## ---------------------------------
##     1     4.1064          1.0000
##     2     2.3380          1.3253
##     3     2.1128          1.3941
##     4     1.3769          1.7269
##     5     1.0991          1.9329
##     6     0.9766          2.0505
##     7     0.8585          2.1871
##     8     0.6731          2.4699
##     9     0.6171          2.5796
##     10     0.5690          2.6865
##     11     0.3779          3.2964
##     12     0.2715          3.8889
##     13     0.2181          4.3391
##     14     0.1967          4.5694
##     15     0.1462          5.3007
##     16     0.0621          8.1343
## ---------------------------------
##  Condition Number         8.1343 
##  Eigenvalues &amp; Cond Index computed from scaled raw sscp (w/ intercept)
##  Det(correlation matrix)    0.0148</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="final-report.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb47-2"><a href="final-report.html#cb47-2" aria-hidden="true" tabindex="-1"></a>glmmPQL_r <span class="ot">&lt;-</span> <span class="fu">glmmPQL</span>(livechat_model, <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span><span class="sc">|</span>AgentName, <span class="at">data =</span> livechat, <span class="at">family =</span> binomial)</span></code></pre></div>
<pre><code>## iteration 1</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="final-report.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glmmPQL_r)</span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: livechat 
##   AIC BIC logLik
##    NA  NA     NA
## 
## Random effects:
##  Formula: ~1 | AgentName
##          (Intercept) Residual
## StdDev: 0.0001919795 1.026964
## 
## Variance function:
##  Structure: fixed weights
##  Formula: ~invwt 
## Fixed effects:  HA_Cls ~ DlvrD + delay_max_std + valcb_spwn_std + i_delay_max_std_rc_dlvrd_rc +      i_valcb_dlvr + drt_std + earlycb_r_std + MCB_IND + cb1bwn_std +      EndChtD + DrCls_IND + lsm_std + DnyD + ha_chat_count_std +      team_d 
##                                  Value Std.Error  DF   t-value p-value
## (Intercept)                 -2.2063583 0.3491458 858 -6.319304  0.0000
## DlvrD                        0.3848989 0.2714842 858  1.417758  0.1566
## delay_max_std               -0.1909658 0.1161801 858 -1.643705  0.1006
## valcb_spwn_std              -0.0439477 0.2057154 858 -0.213634  0.8309
## i_delay_max_std_rc_dlvrd_rc  1.1635117 0.4498096 858  2.586676  0.0099
## i_valcb_dlvr                -0.7557323 0.2600897 858 -2.905660  0.0038
## drt_std                     -0.1834711 0.1250643 858 -1.467014  0.1427
## earlycb_r_std                1.4201864 0.1688229 858  8.412284  0.0000
## MCB_IND                     -0.1123936 0.2117478 858 -0.530790  0.5957
## cb1bwn_std                   0.9892010 0.1703045 858  5.808424  0.0000
## EndChtD                     -1.3023946 0.3651669 858 -3.566573  0.0004
## DrCls_IND                    1.0558608 0.2453534 858  4.303428  0.0000
## lsm_std                      0.3102127 0.1143444 858  2.712969  0.0068
## DnyD                        -0.1746284 0.2025658 858 -0.862082  0.3889
## ha_chat_count_std            0.3109155 0.1369970 858  2.269506  0.0235
## team_d                      -0.1510360 0.2614313  56 -0.577727  0.5658
##  Correlation: 
##                             (Intr) DlvrD  dly_m_ vlcb__ i_____ i_vlc_ drt_st
## DlvrD                       -0.577                                          
## delay_max_std                0.156 -0.264                                   
## valcb_spwn_std              -0.360  0.404 -0.126                            
## i_delay_max_std_rc_dlvrd_rc -0.162  0.163 -0.257  0.152                     
## i_valcb_dlvr                 0.313 -0.134 -0.061 -0.758 -0.158              
## drt_std                      0.027  0.083 -0.409  0.101 -0.063  0.034       
## earlycb_r_std               -0.032 -0.039 -0.140  0.052  0.170 -0.089 -0.309
## MCB_IND                     -0.115 -0.089 -0.114 -0.012 -0.036 -0.031 -0.071
## cb1bwn_std                  -0.059  0.029  0.047  0.118  0.172 -0.103 -0.467
## EndChtD                     -0.089  0.006  0.015  0.008 -0.042 -0.009  0.024
## DrCls_IND                   -0.574 -0.024  0.090  0.086  0.028 -0.099 -0.089
## lsm_std                     -0.016  0.018 -0.066 -0.015 -0.004  0.000 -0.170
## DnyD                        -0.260  0.091 -0.055  0.021 -0.019 -0.001 -0.035
## ha_chat_count_std            0.236  0.052  0.113 -0.019  0.014 -0.033  0.064
## team_d                      -0.364 -0.040 -0.061 -0.008  0.020 -0.046  0.031
##                             erly__ MCB_IN cb1bw_ EndChD DC_IND lsm_st DnyD  
## DlvrD                                                                       
## delay_max_std                                                               
## valcb_spwn_std                                                              
## i_delay_max_std_rc_dlvrd_rc                                                 
## i_valcb_dlvr                                                                
## drt_std                                                                     
## earlycb_r_std                                                               
## MCB_IND                     -0.040                                          
## cb1bwn_std                   0.746  0.051                                   
## EndChtD                      0.008  0.014 -0.027                            
## DrCls_IND                   -0.072  0.006 -0.048  0.013                     
## lsm_std                     -0.122  0.019 -0.172 -0.087 -0.023              
## DnyD                        -0.067 -0.107  0.021  0.060  0.078 -0.067       
## ha_chat_count_std            0.030 -0.065  0.011  0.001 -0.025  0.013 -0.117
## team_d                      -0.004  0.059 -0.012 -0.001 -0.026 -0.031  0.053
##                             h_ch__
## DlvrD                             
## delay_max_std                     
## valcb_spwn_std                    
## i_delay_max_std_rc_dlvrd_rc       
## i_valcb_dlvr                      
## drt_std                           
## earlycb_r_std                     
## MCB_IND                           
## cb1bwn_std                        
## EndChtD                           
## DrCls_IND                         
## lsm_std                           
## DnyD                              
## ha_chat_count_std                 
## team_d                      -0.703
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -6.4283299 -0.5193227 -0.2582833  0.5676998  7.8729503 
## 
## Number of Observations: 930
## Number of Groups: 58</code></pre>
<p>I test the prediction performance through accuracy and ROC. Plm cannot be run with the predict function. Thus, I choose glmmPQL instead which gives the similar results.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="final-report.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predictive accuracy + ROC</span></span>
<span id="cb51-2"><a href="final-report.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plm as model: https://www.princeton.edu/~otorres/Panel101R.pdf</span></span>
<span id="cb51-3"><a href="final-report.html#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co">#plm not working??? with the prdict function</span></span>
<span id="cb51-4"><a href="final-report.html#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co">#https://stackoverflow.com/questions/38623624/usemethodpredict-no-applicable-method-for-predict-applied-to-an-object-o</span></span>
<span id="cb51-5"><a href="final-report.html#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="final-report.html#cb54-1" aria-hidden="true" tabindex="-1"></a>PredProb <span class="ot">&lt;-</span> <span class="fu">predict</span>(glmmPQL_r,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb54-2"><a href="final-report.html#cb54-2" aria-hidden="true" tabindex="-1"></a>Preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(PredProb <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb54-3"><a href="final-report.html#cb54-3" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> <span class="fu">table</span>(Preds,<span class="at">obs=</span>livechat<span class="sc">$</span>HA_Cls)</span>
<span id="cb54-4"><a href="final-report.html#cb54-4" aria-hidden="true" tabindex="-1"></a>tab</span></code></pre></div>
<pre><code>##      obs
## Preds   0   1
##     0 588 120
##     1  71 151</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="final-report.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>((tab[<span class="dv">2</span>, <span class="dv">1</span>] <span class="sc">+</span> tab[<span class="dv">1</span>, <span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(tab))</span></code></pre></div>
<pre><code>## [1] 0.2053763</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="final-report.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Average closing rate or # of 1s.</span></span>
<span id="cb58-2"><a href="final-report.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(livechat<span class="sc">$</span>HA_Cls)</span></code></pre></div>
<pre><code>## [1] 0.2913978</code></pre>
<p>The misclassification rate is 20%. It is better than the 29% random guessing.</p>
<p>I then check the Area under the curve for ROC to show discriminant performance.
I test multiple cut off points since there is a trade off between sensitivity and specificity.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="final-report.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(auc_r)</span></code></pre></div>
<pre><code>## [1] 0.7730067</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="final-report.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co">#??? how to pick the index of the highest value?</span></span>
<span id="cb62-2"><a href="final-report.html#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># filter:  https://www.statology.org/dplyr-filter-not-in/</span></span>
<span id="cb62-3"><a href="final-report.html#cb62-3" aria-hidden="true" tabindex="-1"></a>auc_r[<span class="dv">297</span>]</span></code></pre></div>
<pre><code>## [1] 0.7692131</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="final-report.html#cb64-1" aria-hidden="true" tabindex="-1"></a>thresh[<span class="dv">297</span>]</span></code></pre></div>
<pre><code>## [1] 0.2983333</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="final-report.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co">#https://www.statology.org/auc-in-r/</span></span>
<span id="cb66-2"><a href="final-report.html#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb66-3"><a href="final-report.html#cb66-3" aria-hidden="true" tabindex="-1"></a>Preds_max <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(PredProb <span class="sc">&gt;</span> <span class="fl">0.3</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb66-4"><a href="final-report.html#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(livechat<span class="sc">$</span>HA_Cls, Preds_max)</span></code></pre></div>
<pre><code>## Setting levels: control = 0, case = 1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre><code>## Area under the curve: 0.7692</code></pre>
<p>The area under the curve is 0.77 which is higher than the threshold of 0.7. Thus, the discriminant performance is satisfied.</p>
<p>Finally, I check the residuals.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="final-report.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># residual plot</span></span>
<span id="cb70-2"><a href="final-report.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb70-3"><a href="final-report.html#cb70-3" aria-hidden="true" tabindex="-1"></a>plot_bin <span class="ot">&lt;-</span> <span class="cf">function</span>(Y, X, <span class="at">bins =</span> <span class="dv">100</span>, <span class="at">return.DF =</span> <span class="cn">FALSE</span>){</span>
<span id="cb70-4"><a href="final-report.html#cb70-4" aria-hidden="true" tabindex="-1"></a>Y_Name <span class="ot">&lt;-</span> <span class="fu">deparse</span>(<span class="fu">substitute</span>(Y))</span>
<span id="cb70-5"><a href="final-report.html#cb70-5" aria-hidden="true" tabindex="-1"></a>X_Name <span class="ot">&lt;-</span> <span class="fu">deparse</span>(<span class="fu">substitute</span>(X))</span>
<span id="cb70-6"><a href="final-report.html#cb70-6" aria-hidden="true" tabindex="-1"></a>Binned_Plot <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Plot_Y =</span> Y, <span class="at">Plot_X =</span> X)</span>
<span id="cb70-7"><a href="final-report.html#cb70-7" aria-hidden="true" tabindex="-1"></a>Binned_Plot<span class="sc">$</span>bin <span class="ot">&lt;-</span> <span class="fu">cut</span>(Binned_Plot<span class="sc">$</span>Plot_X,<span class="at">breaks =</span> bins) <span class="sc">|&gt;</span> <span class="fu">as.numeric</span>()</span>
<span id="cb70-8"><a href="final-report.html#cb70-8" aria-hidden="true" tabindex="-1"></a>Binned_Plot_summary <span class="ot">&lt;-</span> Binned_Plot <span class="sc">|&gt;</span></span>
<span id="cb70-9"><a href="final-report.html#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="fu">group_by</span>(bin) <span class="sc">|&gt;</span></span>
<span id="cb70-10"><a href="final-report.html#cb70-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summarise</span>(<span class="at">Y_ave =</span> <span class="fu">mean</span>(Plot_Y),</span>
<span id="cb70-11"><a href="final-report.html#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="at">X_ave =</span> <span class="fu">mean</span>(Plot_X),</span>
<span id="cb70-12"><a href="final-report.html#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="at">Count =</span> <span class="fu">n</span>()) <span class="sc">|&gt;</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb70-13"><a href="final-report.html#cb70-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> Binned_Plot_summary<span class="sc">$</span>Y_ave, <span class="at">x =</span> Binned_Plot_summary<span class="sc">$</span>X_ave,</span>
<span id="cb70-14"><a href="final-report.html#cb70-14" aria-hidden="true" tabindex="-1"></a><span class="at">ylab =</span> Y_Name, <span class="at">xlab =</span> X_Name)</span>
<span id="cb70-15"><a href="final-report.html#cb70-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(return.DF) <span class="fu">return</span>(Binned_Plot_summary)</span>
<span id="cb70-16"><a href="final-report.html#cb70-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb70-17"><a href="final-report.html#cb70-17" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_bin</span>(<span class="at">Y =</span> <span class="fu">residuals</span>(glmmPQL_r), <span class="at">X =</span> <span class="fu">predict</span>(glmmPQL_r,<span class="at">type=</span><span class="st">&quot;response&quot;</span>), <span class="at">bins =</span> <span class="dv">200</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="final-report.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#??? the variance is so much bigger close to 1? on a few observations. what does it mean? predict 1 but 0???</span></span></code></pre></div>
<p>The result plots show that most of the range the prediction is good except when it is very close to 1.
Thus, the model fits the data well.</p>
</div>
<div id="interpretation-of-the-fixed-effect-coefficients" class="section level4 hasAnchor" number="14.2.2.3">
<h4><span class="header-section-number">14.2.2.3</span> Interpretation of the fixed effect coefficients<a href="final-report.html#interpretation-of-the-fixed-effect-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="final-report.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretation ??? probability goes above 1? increase by 76%?</span></span>
<span id="cb72-2"><a href="final-report.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co">#simple effect of concession tactic</span></span>
<span id="cb72-3"><a href="final-report.html#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">exp</span>(<span class="fl">0.3848989</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="fl">0.3848989</span>)))  </span></code></pre></div>
<pre><code>## [1] 0.5950541</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="final-report.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction effect when used with delay 1SD</span></span>
<span id="cb74-2"><a href="final-report.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">exp</span>(<span class="fl">1.1635117</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="fl">1.1635117</span>))) </span></code></pre></div>
<pre><code>## [1] 0.7619702</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="final-report.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction effect when used with value affirmation 1SD</span></span>
<span id="cb76-2"><a href="final-report.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">exp</span>(<span class="sc">-</span><span class="fl">0.7557323</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">0.7557323</span>))) </span></code></pre></div>
<pre><code>## [1] 0.3195735</code></pre>
<p>The results show that concession tactics increases the sales closing likelihood by 60% when everything else is at their mean level (i.e., x = 0). The result is not significant (p&gt;0.1) when not considered the interactions with delay and value affirmation tactics (i.e., at the mean level of delay and value affirmation tactics).</p>
<p>When the concession is used with the delay tactic (1 SD+), the sales closing likelihood further increases by 76% (p &lt; 0.05).
When the concession tactic is used with value affirmation tactic (1 SD+), the sales closing likelihood decreases by 32% (p &lt; 0.05).</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="final-report.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co">#??? Test using HA team as instrument</span></span></code></pre></div>
</div>
</div>
<div id="research-implications" class="section level3 hasAnchor" number="14.2.3">
<h3><span class="header-section-number">14.2.3</span> Research Implications<a href="final-report.html#research-implications" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Retailers intended live chat to be an information portal, but it became a bargain hunt that empowers consumers to sweeten the deal.
salespeople need to gain a nuanced understanding of how to close the sale with scarcity mindset consumers.
When cues do not fit consumers’ information-processing mode, the cues can backfire.
Thus, the adage less is more applicable for live-chat negotiation.
I demonstrated that concurrent use of the concession tactic and the delay tactic is more effective.
In contrast, concurrent use with the value affirmation tactic can even decrease the likelihood of closing sales, despite more efforts exerted by salespeople, since the tactic does not fit the heuristic processing of information activated by the concession tactic.
Thus, the business may want salespeople to either use the value affirmation tactic throughout the chat or the concession tactic, but not both.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="final-report.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Q&amp;A </span></span>
<span id="cb79-2"><a href="final-report.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="co">#??? a) residual centering then how to interpret or show the results look simiar and use uncentered? otherwise, how to solve multi-corr. b) prediction accuracy cut-off ROC  c) can I test the squared relationship when the corr is high? d) optional: instrument. on the effect on the second level? </span></span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="applied-stats-model-ii-lecture-note.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="experimental-data-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lyf718718/Book2.git/edit/master/ASM2_Term_Project.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/lyf718718/Book2.git/blob/master/ASM2_Term_Project.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
