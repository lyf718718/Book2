---
title: "ASM Exam 1_ Yufan Lin"
author: "Yufan Lin"
date: "3/7/2022"
output: html_document
---

```{r ASM_Exam1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Applied Stats Model II - Exam 1

## 1. (7 points) In a poisson regression problem with one explanatory variable x, the estimate of the β

coefficient under a log link is βˆ = 0.5. If, when x = 1 we can obtain a predicted count of µˆ = 4. What is the predicted count when x = 3?

```{r}
# since the link is log, I transform it back to the count or 1.65
exp(0.5)
#the intercept is 3.5 #??? does the intercept needs the log? 
#4- 1*0.5  
#when x = 3, 3*beta = 4.95 
3 * 1.65 
#Thus, the predicted count is 
3.5 + 4.95 
```

The predicted count when the x =3 is 8.45 times.

## 2. (5 points) In a generalized linear model, why is the null deviance typically larger than the residual deviance?

The null model only contains the intercept, while the residual deviance comes from the model with other predictors. If the other predictors are useful in the prediction, the deviance will be smaller.

## 3. (5 points) Can standard linear regression ever be used when the data are counts? Explain why or why not.

Yes it can run and predict the counts as the count can be expressed linearly. However, the result won't be valid. First, the count data are strickly 0 or positive. linear regression will lead to negative prediction. Second, The distribution of error terms won't be normal as there is often 0 inflation in the count data.

## 4. Take the following random effect model

yij = µ + αi + εij . This model was fit using lmer() and analyzed with the below. TheModel \<- lmer(y \~ (1 \| alpha), data= TheData) summary(TheModel) ## Linear mixed model fit by REML \['lmerMod'\] ## Formula: y \~ (1 \| alpha) ## Data: TheData ## ## REML criterion at convergence: 5035925 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -5.0460 -0.6744 -0.0009 0.6759 4.6942 ## ## Random effects: ## Groups Name Variance Std.Dev. ## alpha (Intercept) 2.435 1.561 ## Residual 9.007 3.001 ## Number of obs: 1000000, groups: alpha, 10 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 14.9258 0.4935 30.25 ranef(TheModel)\$alpha ## (Intercept) ## 1 1.8086783 ## 2 -0.5872736 ## 3 2.2398284 ## 4 -1.5152633 ## 5 0.1962228 ## 6 -2.0713461 ## 7 0.5250623 ## 8 -2.0133227 ## 9 -0.1044895 ## 10 1.5218990

### 

Complete the following:

### (3 points) Find the intra class correlation coefficient.

```{r}
#S7 MM-RandomEffects_Spring2022
# ICC is the alpha variance out of total variance
ICC = 2.435 / (2.435 + 9.007)
ICC
```

The intra class correlation is 0.21

### (2 points) Which level of the random effect α will have the largest predicted value?

at level 3, as the coefficient is 2.23

### (2 points) Predict y for level 6 of the random effect.

```{r}
#S23 MM-RandomEffects_Spring2022
# fixed effect intercept + random effect at level 6
14.9258 +  -2.0713461

```

The predicted y will be 12.85

## 5. Utilizing the below code and output, answer the following:

### • (3 points) Why are the residual and null deviance values the same?

They are the same since the model only contains the intercept which essentially is the null model.

### • (2 points) Based on these deviance values, does the model "fit" well? Does this make sense?

It doesn't fit well as the variance is as large as the null model. It make sense, since they are the same model.

```{r}
SomeData <- rgamma(n = 30, shape = 1.5, scale = 1.5)
AModel <- glm( SomeData ~ 1, family = Gamma )
summary(AModel)
```

## 

## 6. Take the data given by Problem6Data.csv, which contains a continuous response y and two predictors x1 and x2.

```{r}
P6 <- read.csv("E:/Cloud/OneDrive - University of Missouri/Mizzou_PhD/Class plan/Applied Stats Model II/Exam1/Problem6Data.csv", stringsAsFactors = TRUE)
```

### a. (5 points) Read the data into R and make some plots between the response and predictors. Describe the patterns and comment on behaviors you observe with exact 0s.

```{r}
plot(y ~ x1,P6)
plot(y ~ x2,P6)
```

```{r}
library(tidyverse) # for mutate function
Plot_DF <- P6 |>
group_by(y) |>
summarise(count=n()) |> #n() is the summarise function option
mutate(etotal=sum(count), proportion=count/etotal)
Plot_DF
```

The y and x1 and x2 have a positive relationship. as x1 or x2 increases the y also increases.

There are 10% of y are 0s.

### b. (5 points) Make a histogram of the response variable and comment on the shape. Are the values strictly positive?

```{r}
hist(P6$y)
```

The response variable is highly right skewed with many 0s. The values are 0 and positive.

### c. (4 points) State the range that the index parameter p, for use in the Tweedie distribution, must be contained in. Why is this the case?

The range should be seq(from=1.2,to=1.8,by=0.1) since there are 0s and positive values.

### d. (6 points) Find an optimal value of p for use in the Tweedie Distribution, using a log link.

```{r}
# why sometimes work, sometimes doesn't???
library(tweedie)

TW_p_log <- tweedie.profile(y ~ .,
p.vec = seq(from=1.2,to=1.8,by=0.05),
link.power = 0, do.plot = TRUE,# log link
data=P6)
```

```{r}
Tweedie_p_log = TW_p_log$p.max

Tweedie_p_log
```

The optimal value is 1.32

### e. (5 points) Again using a log link, fit a Tweedie Distribution using the index parameter value you obtained in part d.

```{r}
library(statmod) # For tweedie family in glm()

clot_Tweedie_log <- glm(y ~ ., data=P6,
family=tweedie(var.power=TW_p_log$p.max,link.power=0))

```

```{r}
summary(clot_Tweedie_log)
```

### f. (6 points) For each of the values of x2 given by the R vector x2_vals \<- seq(0, 15, by= .01), use the compound Poisson-Gamma structure to predict the probability of obtaining an exact 0 response when x1 is at its mean value.

```{r}
summary(P6)
```

```{r}
# Generate the new dataset. 
# create a new dataset with x2 taking all value, x1 taking mean. Then the count using the new data. 
data_x2 <- data.frame(x2 = seq(0, 15, by= .01))
data_x1 <- data.frame(x1 = runif(n = 1501, min = 7.50728, max = 7.50728))
data_gen = cbind(data_x1,data_x2)

```

```{r}
mu.data_gen <- predict(clot_Tweedie_log, newdata=data_gen,type="response")
p_MLE <- TW_p_log$p.max
phi_MLE <- TW_p_log$phi.max
#mu.data_gen
Prob_Zero_Model <- exp(-mu.data_gen^(2 - p_MLE)/(phi_MLE*(2 - p_MLE)))
```

```{r}
summary(Prob_Zero_Model)
```

The probability to attain 0 response when x1 is at its mean is 4.5%.

```{r}
# produce the actual 0 vs. predicted 0 comparison
#library(tidyverse)
#quilpie |> group_by(Phase) |> summarize(prop0_dat = mean(Rain==0)) |> cbind(Prob_Zero_Model)
#??? why is the actual data 10% 0, but here is 4.5%? Diff so much
```

## 7. The ships dataset in the MASS package provides the number of incidents(indicents) resulting in ship damage as a function of total months of service(service), ship type(type), as well as: • Year of ship construction(year) -- Broken into 5 year increments with the year's variable value indicating the beginning of this period. e.g. year=60 refers to 1960-1964 • Period of operation(period) with realizations: -- 60: 1960 - 1974 -- 75: 1975 - 1979 The data can be loaded with: data(ships, package="MASS")

```{r}
data(ships, package="MASS")
```

### a. (4 points) Use group_by and summarise to compute the average months of service for each combination of year of construction and period of operation. Explain why there is a 0 in the result.

```{r}
#ships$year <- as.factor(ships$year)
#ships$period <- as.factor(ships$period)

library(tidyverse) # for mutate function
Plot_DF_Service <- ships |>
group_by(year, period) |>
summarise(mean=mean(service)) #variable name is mean

#Plot_DF_Service
#??? https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/summarise
# Why does it need mean = mean()? duplication?
```

```{r Q7a}
Plot_DF_Service
# then why the 70 and 60 combination has service???
```

The 0 appears when the construction year is 75 (1975-1979) and the period of operation is 60 (1960-1964). The ship's construction is after its period of operation, thus no service is recorded.

### b. (3 points) Create a new filtered dataset by removing the rows where service=0.

```{r}
library(dplyr) #must run the library again to avoid the duplicated names
# filter the data
ships_filter = filter(ships, ships$service > 0)

```

### c. (10 points) Fit both a Poisson rate model and Negative Binomial rate model model using number of incidents per service month as the response and all other variables as predictors. Compare which model is better using AIC.

```{r}
# is it the aggregated model vs. individual count? or the same???
# using the filtered data?

ships_filter$incidents_month = ships_filter$incidents / ships_filter$service


```

```{r}
Poisson_Mod <- glm(incidents ~ year + period + type + service, family=poisson, ships_filter)
summary(Poisson_Mod)

```

```{r Q7c}
NegBinom_Mod <- MASS::glm.nb(incidents ~ year + period + type + service, ships_filter)
# Convert back to glm() style object ??? why needs a conversion? 
# why alternative style reached?
NegBinom_Mod_glm <- MASS::glm.convert(NegBinom_Mod)
summary(NegBinom_Mod_glm, dispersion=1)
```

### d. (7 points) Using the better model selected in part c, assess the significance of each term using drop1(). Which terms are insignificant? Remove the insignificant variables from the model in c, and refit.

```{r}
#Neg binomial is better. 

drop1(NegBinom_Mod,test="F")
```

All the terms are significant at 95% confidence level.

### e. (6 points) Statistically compare the residual deviance in your final model from d to the null deviance.

```{r}
pchisq(summary(NegBinom_Mod)$deviance,NegBinom_Mod$df.residual, lower.tail = FALSE)
```

The difference is significant at 95 % confidence level. Thus, the model in d is significantly better than the null model.

### f. (4 points) Compare the AIC from the reduced model in d to the corresponding value from c. Is the change you see expected? Also examine the residual deviance of the model in d, what does it say about the model's fit to the data?

```{r}
#??? all are significant no change?
```

Reduced model's lowest AIC is 181 vs. the model in c is 183. The change is very small since the reduced model essentially is the same as the c (i.e., all variables are significant predictors).

Residual variance in d 42 or the same as the c. The model fits the data well.

### g. (6 points) Make a plot of the deviance residuals vs the predicted values(link scale). How is the fit?

```{r}
library(DALEX)
library(auditor)

i_NegBiExp <- DALEX::explain(NegBinom_Mod, data = ships_filter, y = ships_filter$incidents,verbose = FALSE)
i_NegBiHalfNorm <- model_halfnormal(i_NegBiExp)

#S16

plot_halfnormal(i_NegBiHalfNorm, quantiles = TRUE)

#S30
#Error: 'model_halfnormal' is not an exported object from 'namespace:DALEX' -> need auditor library. 

```

The fit is good. There is no over-dispersion issue anymore.
